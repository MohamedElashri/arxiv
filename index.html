<!DOCTYPE html>
<html lang="en">

<head>
    <title>ME Arxiv Daily</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <a href="https://melashri.net/arxiv/" style="text-decoration: none;">
                <div class="header-title">
                    <span class="header-title-preffix">My</span>Arxiv Feed
                </div>
            </a>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2025-09-11T00:00:00Z">2025-09-11</time>
        </div>
            <article>
                <details>
                    <Summary>
                        High Energy Physics - Experimental
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are arXiv submissions on Wednesday better cited? Introducing Big Data
  methods in undergraduate courses on scientific computing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stéphane Delorme, Leon Mach, Hubert Paszkiewicz, Richard Ruiz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extracting information from big data sets, both real and simulated, is a
modern hallmark of the physical sciences. In practice, students face barriers
to learning ``Big Data'' methods in undergraduate physics and astronomy
curricula. As an attempt to alleviate some of these challenges, we present a
simple, farm-to-table data analysis pipeline that can collect, process, and
plot data from the 800k entries common to the arXiv preprint repository and the
bibliographical database inSpireHEP. The pipeline employs contemporary research
practices and can be implemented using open-sourced Python libraries common to
undergraduate courses on Scientific Computing. To support the use such
pipelines in classroom contexts, we make public an example implementation,
authored by two undergraduate physics students, that runs on off-the-shelf
laptops. For advanced students, we discuss applications of the pipeline,
including for online DAQ monitoring and commercialization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 8 figures, 2 tables, 1 listing, project available at
  https://gitlab.cern.ch/riruiz/public-projects/-/tree/master/BibAPI/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mapping of discrete range modulated proton radiograph to
  water-equivalent path length using machine learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09514v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09514v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atiq Ur Rahman, Chun-Chieh Wang, Shu-Wei Wu, Tsi-Chian Chao, I-Chun Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objective. Proton beams enable localized dose delivery. Accurate range
estimation is essential, but planning still relies on X-ray CT, which
introduces uncertainty in stopping power and range. Proton CT measures water
equivalent thickness directly but suffers resolution loss from multiple Coulomb
scattering. We develop a data driven method that reconstructs water equivalent
path length (WEPL) maps from energy resolved proton radiographs, bypassing
intermediate reconstructions. Approach. We present a machine learning pipeline
for WEPL from high dimensional radiographs. Data were generated with the TOPAS
Monte Carlo toolkit, modeling a clinical nozzle and a patient CT. Proton
energies spanned 70-230 MeV across 72 projection angles. Principal component
analysis reduced input dimensionality while preserving signal. A conditional
GAN with gradient penalty was trained for WEPL prediction using a composite
loss (adversarial, MSE, SSIM, perceptual) to balance sharpness, accuracy, and
stability. Main results. The model reached a mean relative WEPL deviation of
2.5 percent, an SSIM of 0.97, and a proton radiography gamma index passing rate
of 97.1 percent (2 percent delta WEPL, 3 mm distance-to-agreement) on a
simulated head phantom. Results indicate high spatial fidelity and strong
structural agreement. Significance. WEPL can be mapped directly from proton
radiographs with deep learning while avoiding intermediate steps. The method
mitigates limits of analytic techniques and may improve treatment planning.
Future work will tune the number of PCA components, include detector response,
explore low dose settings, and extend multi angle data toward full proton CT
reconstruction; it is compatible with clinical workflows.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Chromatic Calorimetry -- A Novel Approach to Validate Energy Resolution
  and Particle Discrimination 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09511v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09511v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Devanshi Arora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chromatic calorimetry (CCAL) analyses particle detection by utilizing
scintillators with distinct emission wavelengths to measure the longitudinal
energy deposition of particle showers in high-energy physics, improving
particle identification (PID) and energy resolution. By stacking scintillators
in order of decreasing emission wavelength, CCAL enables layer-specific energy
measurements, analyzed via amplitude fractions ($f_i = A_i / \sum_j A_j$) and
center of gravity ($\langle z_{\text{cog}} \rangle = \sum_i z_i E_i / \sum_i
E_i$). This thesis presents results from two CERN Super Proton Synchrotron
(SPS) experiments conducted in 2023 and 2024, complemented by GEANT4
simulations of a quantum dot (QD)-based CCAL design, to validate its potential
for future colliders such as the Future Circular Collider (FCC).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PhD thesis</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Long-term operation of the screen-printed graphite-based resistive
  coatings on the HPL electrode for the Resistive Plate Chamber 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09433v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09433v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Costa, Francesco Fallavollita, Hubert Kroha, Oliver Kortner, Pavel Maly, Giorgia Proto, Daniel Soyk, Elena Voevodina, Jorg Zimmermann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The reliability of large-area Resistive Plate Chambers (RPCs) operated under
High-Luminosity Large Hadron Collider (HL-LHC) conditions is governed by the
long-term stability and radiation tolerance of screen-printed graphite/phenoxy
coatings on high-pressure-laminate (HPL) electrodes. This work presents a
comprehensive, end-to-end qualification of such coatings that integrates
industrial process control and metrology with controlled humidity/temperature
campaigns, extended high-voltage stress testing to decade-scale charge levels,
and representative neutron and gamma irradiation at CERN facilities. The
results establish reproducible industrial coating production, stable
performance under sustained operation and irradiation, and practical acceptance
criteria with operating and monitoring guidelines. The study provides a
transferable quality-assurance framework for graphite-based resistive coatings
on HPL electrodes, enabling reproducible production and reliable RPC
performance for the HL-LHC upgrades and for future high-rate collider
experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Determination of <span class="highlight-title">CKM</span> matrix element and axial vector form factors from
  weak decays of quantum-entangled <span class="highlight-title">strange</span> baryons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09266v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09266v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. C. Liu, Lu Liu, M. H. Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. L. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, Heng Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, Zirong Song, S. Sosio, S. Spataro, S Stansilaus, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, Shun Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, S. H. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan,  Zhang, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The electromagnetic structure of the nucleon can be determined from the
scattering of electrons off a nucleon target. However, to study its axial
structure, neutrino beams are required. The results from these experiments
should be extrapolated to zero energy-momentum transfers to access the static
properties of the nucleon. For baryons with strange quarks, hyperons, the
static limit can instead be approached in semi-leptonic decays, which give
direct access to the weak magnetism and axial-vector coupling strengths that
are inaccessible in electromagnetic interactions. The axial-vector coupling as
while weak magnetism coupling and the overall normalization, given by form
factor $f_1$, are being determined with increased precision from the theory of
strong interactions using a first principles formulation on the space--time
lattice. Furthermore, the probability of the semi-leptonic hyperon decay is
approximately proportional to $|V_{us}|^2\cdot (f_1^2+3g_1^2)$, where $V_{us}$
is the CKM matrix element responsible for the transition between an $s$ and a
$u$ quark. Current determinations of $|V_{us}|$ come from kaon decays, but the
results are not consistent and could indicate a deviation from CKM matrix
unitarity, a tell-tale sign of physics beyond the Standard Model (SM) of
elementary particles. Here we determine the absolute branching fraction and
weak coupling strengths for $\Lambda\to p e^-\bar\nu_e$, and $\bar \Lambda\to
\bar p e^+\nu_e$. These observables combined with form factors determined from
first-principle lattice QCD calculations allow for the extraction of the
$|V_{us}|$ value. We demonstrate how $|V_{us}|$ can be extracted with
increasing sensitivity using polarized hyperons from entangled,
baryon-antibaryon pairs, thus enabling a complementary road to that of meson
decays. In addition, the presented experimental method can be used for other
semileptonic decays of baryons.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TCT-based monitoring of LGAD radiation hardness for <span class="highlight-title">ATLAS</span>-HGTD
  production 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09187v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09187v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iskra Velkovska, Bojan Hiti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Production of the High Granularity Timing Detector for the ATLAS experiment
at High Luminosity LHC requires over 21000 silicon sensors based on Low Gain
Avalanche Diode (LGAD) technology. Their radiation hardness is monitored as a
part of the production quality control. Dedicated test structures from each
wafer are irradiated with neutrons and a fast and comprehensive
characterization is required. We introduce a new test method based on Transient
Current Technique (TCT) performed in the interface region of two LGAD devices.
The measurement enables extraction of numerous sensor performance parameters,
such as LGAD gain layer depletion voltage, LGAD gain dependence on bias
voltage, sensor leakage current and effective interpad distance. Complementary
capacitance-voltage measurements and charge collection measurements with 90Sr
on the same samples have been performed to calibrate the TCT results in terms
of charge collection and define acceptance criteria for wafer radiation
hardness in the ATLAS-HGTD project.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Observation of $ψ(3686)\to γη(1405)$ via $η(1405)\to
  f_0(980)π^0$ 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09156v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09156v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. L. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, Heng Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, Zirong Song, S. Sosio, S. Spataro, S Stansilaus, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan,  Zhang, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The decay $\psi(3686)\to\gamma\pi^+\pi^-\pi^0$ is studied using a sample of
$(2712.4\pm14.3)\times10^6$ $\psi(3686)$ events collected with the BESIII
detector. The decay $\eta(1405)\to\pi^+\pi^-\pi^0$ is observed for the first
time in $\psi(3686)$ decays via the intermediate state $f_0(980)$ and the
product branching fraction
$\mathcal{B}(\psi(3686)\to\gamma\eta(1405))\times\mathcal{B}(\eta(1405)\to
f_0(980)\pi^0)\times \mathcal{B}(f_0(980)\to\pi^+\pi^-)$ is determined to be
$(3.77\pm0.43\pm0.29)\times10^{-7}$, where the first uncertainty is statistical
and the second is systematic. The isospin-violating decay of
$\psi(3686)\to\gamma f_1(1285)\to\gamma f_0(980)\pi^0\to\gamma\pi^+\pi^-\pi^0$
has been observed with signal significance of $2.9\sigma$. And the branching
fraction $\mathcal{B}(\psi(3686)\to\gamma f_1(1285)\to\gamma
f_0(980)\pi^0\to\gamma\pi^+\pi^-\pi^0)$ is determined to be $
(7.36\pm2.25\pm2.26)\times 10^{-8}$. Since no $\eta_c$ signal is evident in
either the $\pi^+\pi^-\pi^0$ or $f_0(980)\pi^0$ mass spectrum, upper limits are
set to be
$\mathcal{B}(\psi(3686)\to\gamma\eta_c)\times\mathcal{B}(\eta_c\to\pi^+\pi^-\pi^0)<3.09\times10^{-7}$
and $\mathcal{B}(\psi(3686)\to\gamma\eta_c)\times\mathcal{B}(\eta_c\to
f_0(980)\pi^0)\times\mathcal{B}(f_0(980)\to\pi^+\pi^-)<7.97\times10^{-8}$ at
90\% confidence level, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ R-parity violation and 8 TeV four-<span class="highlight-title">jet</span> events at the LHC: a falsification
  opportunity for Wagner's Rule 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09062v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09062v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pedro Bittar, Subhojit Roy, Carlos E. M. Wagner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The CMS Collaboration at the Large Hadron Collider (LHC) has observed two
four-jet events with a total invariant mass of about 8 TeV; within each event,
the jets can be paired into two dijets with invariant masses of 2 TeV each.
These are extremely rare events due to the large invariant mass, which implies
a very small QCD background, as well as to the di-jet structure, which makes it
prone to an interpretation in terms of a heavy resonance decaying into two
lighter ones. We investigate the possible interpretation of these events in
terms of supersymmetry with a single baryon-number and R-Parity violating term.
Such an interpretation would be in accordance with Wagner's rule, which asserts
that any collider anomaly may be explained by low-energy Supersymmetry when
R-Parity-violating couplings are allowed. In this particular scenario, the
lighter resonances are identified with the right-handed squarks of the first
generation, while the heavy one is interpreted in terms of a down-squark of the
second or third generation. We discuss the constraints that shape this
interpretation and outline a well-defined scenario for its realization. The
resulting predictions can be scrutinized with forthcoming LHC data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 2 Figures, 2 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do QGP Droplets Drive Anisotropy in Small Systems? Insights from RHIC
  and the LHC 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.21183v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.21183v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roy A. Lacey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Azimuthal anisotropy scaling functions for identified mesons and baryons are
analyzed in large (Pb+Pb at $\sqrt{s_{NN}} = 2.76$ and 5.02 TeV, Au+Au at
$\sqrt{s_{NN}} = 200$ GeV), intermediate (Cu+Cu at $\sqrt{s_{NN}} = 200$~GeV),
and small (p+Pb at $\sqrt{s_{NN}} = 5.02$ and 8.16 TeV, p+Au, d+Au, and
$^3$He+Au at $\sqrt{s_{NN}} = 200$ GeV) collision systems. The scaling
functions' fidelity supports a hydrodynamic-like origin for anisotropies in the
flow-dominated regime. Central Pb+Pb, Au+Au, and Cu+Cu reflect QGP-driven
expansion with strong radial flow and significant jet quenching, while
peripheral Pb+Pb and Cu+Cu exhibit hadronic-dominated dynamics. In contrast,
central RHIC small systems show hadronic-dominated behavior, with strong
re-scattering, negligible radial flow, and suppressed jet quenching, following
the hierarchy p+Au $>$ d+Au $>$ $^3$He+Au. At the LHC, ultra-central p+Pb
collisions display enhanced radial flow, reduced re-scattering, and small but
nonzero jet quenching. Scaling violations at high $p_T$ reflect partial
suppression of partonic energy loss. These findings demonstrate that QGP-like
behavior in small systems depends sensitively on both system size and beam
energy, and establish the scaling framework as a robust diagnostic of
collectivity and medium properties across diverse collision conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Seven pages, four figures, submitted for publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Early Career Researcher Input to the European Strategy for Particle
  Physics Update: White Paper 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.19862v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.19862v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan-Hendrik Arling, Alexander Burgman, Christina Dimitriadi, Ulrich Einhaus, Axel Gallén, Abdelhamid Haddad, Laura Huhta, Armin Ilg, Jan Klamka, Elizabeth Long, Thomas Madlener, Arnau Morancho Tardà, Emanuela Musumeci, Krzysztof Mękała, Elena Pompa Pacchi, Marvin Pfaff, Daniel Reichelt, Leonhard Reichenbach, Birgit Stapf, Francesco P. Ucci, Erik Wallin, Harriet Watson, Sagar Vidya Addepalli, Bruno Alves, Robert Mihai Amarinei, Ricardo Barrué, Lydia Brenner, Giacomo Da Molin, Arturo de Giorgi, Bohdan Dudar, Francesco Giuli, Andrea Gurgone, César Jesús-Valls, Antoine Laudrain, Martin J. Losekamm, Rafał Masełek, Wrishik Naskar, Miquel Nebot-Guinot, Marko Pesut, Thomas Pöschl, Efrain P. Segarra, Rebecca Taylor, Pavel Vana, Hannah Wakeling, Aidan R. Wiederhold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This document, written by early career researchers (ECRs) in particle
physics, aims to represent the perspectives of the European ECR community and
serves as input for the 2025--2026 update of the European Strategy for Particle
Physics. With input from a community-wide survey, it highlights key challenges
faced by ECRs -- career stability, funding access and long-term research
opportunities -- while proposing policy recommendations and targeted
initiatives. It underscores the importance of practices fostering diverse,
equitable, inclusive and healthy workplaces, as well as of stronger ECR
communities, and highlights how effective communication and interdisciplinary
collaborations reinforce the societal relevance of particle physics and promote
continued support for large-scale and long-term projects. Finally, the future
of both collider and beyond-collider experiments is addressed, emphasising the
critical role of ECRs in shaping future projects. The ECR contribution is
formed of two parts: the ten-page executive summary submitted as input to the
European Strategy for Particle Physics Update and, as backup document, this
extended white paper providing additional context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Endorsed by the ECFA ECR Panel. Editor and author attribution in the
  document</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adapting Vision-Language Models for Neutrino Event Classification in
  High-Energy Physics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08461v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08461v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Large Language Models (LLMs) have demonstrated their
remarkable capacity to process and reason over structured and unstructured data
modalities beyond natural language. In this work, we explore the applications
of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa
3.2, to the task of identifying neutrino interactions in pixelated detector
data from high-energy physics (HEP) experiments. We benchmark this model
against a state-of-the-art convolutional neural network (CNN) architecture,
similar to those used in the NOvA and DUNE experiments, which have achieved
high efficiency and purity in classifying electron and muon neutrino events.
Our evaluation considers both the classification performance and
interpretability of the model predictions. We find that VLMs can outperform
CNNs, while also providing greater flexibility in integrating auxiliary textual
or semantic information and offering more interpretable, reasoning-based
predictions. This work highlights the potential of VLMs as a general-purpose
backbone for physics event classification, due to their high performance,
interpretability, and generalizability, which opens new avenues for integrating
multimodal reasoning in experimental neutrino physics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The anomalous magnetic moment of the muon in the Standard Model: an
  update 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.21476v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.21476v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R. Aliberti, T. Aoyama, E. Balzani, A. Bashir, G. Benton, J. Bijnens, V. Biloshytskyi, T. Blum, D. Boito, M. Bruno, E. Budassi, S. Burri, L. Cappiello, C. M. Carloni Calame, M. Cè, V. Cirigliano, D. A. Clarke, G. Colangelo, L. Cotrozzi, M. Cottini, I. Danilkin, M. Davier, M. Della Morte, A. Denig, C. DeTar, V. Druzhinin, G. Eichmann, A. X. El-Khadra, E. Estrada, X. Feng, C. S. Fischer, R. Frezzotti, G. Gagliardi, A. Gérardin, M. Ghilardi, D. Giusti, M. Golterman, S. Gonzàlez-Solís, S. Gottlieb, R. Gruber, A. Guevara, V. Gülpers, A. Gurgone, F. Hagelstein, M. Hayakawa, N. Hermansson-Truedsson, A. Hoecker, M. Hoferichter, B. -L. Hoid, S. Holz, R. J. Hudspith, F. Ignatov, L. Jin, N. Kalntis, G. Kanwar, A. Keshavarzi, J. Komijani, J. Koponen, S. Kuberski, B. Kubis, A. Kupich, A. Kupść, S. Lahert, S. Laporta, C. Lehner, M. Lellmann, L. Lellouch, T. Leplumey, J. Leutgeb, T. Lin, Q. Liu, I. Logashenko, C. Y. London, G. López Castro, J. Lüdtke, A. Lusiani, A. Lutz, J. Mager, B. Malaescu, K. Maltman, M. K. Marinković, J. Márquez, P. Masjuan, H. B. Meyer, T. Mibe, N. Miller, A. Miramontes, A. Miranda, G. Montagna, S. E. Müller, E. T. Neil, A. V. Nesterenko, O. Nicrosini, M. Nio, D. Nomura, J. Paltrinieri, L. Parato, J. Parrino, V. Pascalutsa, M. Passera, S. Peris, P. Petit Rosàs, F. Piccinini, R. N. Pilato, L. Polat, A. Portelli, D. Portillo-Sánchez, M. Procura, L. Punzi, K. Raya, A. Rebhan, C. F. Redmer, B. L. Roberts, A. Rodríguez-Sánchez, P. Roig, J. Ruiz de Elvira, P. Sánchez-Puertas, A. Signer, J. W. Sitison, D. Stamen, D. Stöckinger, H. Stöckinger-Kim, P. Stoffer, Y. Sue, P. Tavella, T. Teubner, J. -N. Toelstede, G. Toledo, W. J. Torres Bobadilla, J. T. Tsang, F. P. Ucci, Y. Ulrich, R. S. Van de Water, G. Venanzoni, S. Volkov, G. von Hippel, G. Wang, U. Wenger, H. Wittig, A. Wright, E. Zaid, M. Zanke, Z. Zhang, M. Zillinger, C. Alexandrou, A. Altherr, M. Anderson, C. Aubin, S. Bacchio, P. Beltrame, A. Beltran, P. Boyle, I. Campos Plasencia, I. Caprini, B. Chakraborty, G. Chanturia, A. Crivellin, A. Czarnecki, L. -Y. Dai, T. Dave, L. Del Debbio, K. Demory, D. Djukanovic, T. Draper, A. Driutti, M. Endo, F. Erben, K. Ferraby, J. Finkenrath, L. Flower, A. Francis, E. Gámiz, J. Gogniat, A. V. Grebe, S. Gündogdu, M. T. Hansen, S. Hashimoto, H. Hayashii, D. W. Hertzog, L. A. Heuser, L. Hostetler, X. T. Hou, G. S. Huang, T. Iijima, K. Inami, A. Jüttner, R. Kitano, M. Knecht, S. Kollatzsch, A. S. Kronfeld, T. Lenz, G. Levati, Q. M. Li, Y. P. Liao, J. Libby, K. F. Liu, V. Lubicz, M. T. Lynch, A. T. Lytle, J. L. Ma, K. Miura, K. Möhling, J. Muskalla, F. Noël, K. Ottnad, P. Paradisi, C. T. Peterson, A. Pich, S. Pitelis, S. Plura, A. Price, D. Radic, A. Radzhabov, A. Risch, S. Romiti, S. Sahoo, F. Sannino, H. Schäfer, Y. Schelhaas, S. I. Serednyakov, O. Shekhovtsova, J. N. Simone, S. Simula, E. P. Solodov, F. M. Stokes, M. Vanderhaeghen, A. Vaquero, N. Vestergaard, W. P. Wang, Z. Wąs, K. Yamashita, Y. B. Yang, T. Yoshioka, C. Z. Yuan, A. S. Zhevlakov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the current Standard Model (SM) prediction for the muon anomalous
magnetic moment, $a_\mu$, updating the first White Paper (WP20) [1]. The pure
QED and electroweak contributions have been further consolidated, while
hadronic contributions continue to be responsible for the bulk of the
uncertainty of the SM prediction. Significant progress has been achieved in the
hadronic light-by-light scattering contribution using both the data-driven
dispersive approach as well as lattice-QCD calculations, leading to a reduction
of the uncertainty by almost a factor of two. The most important development
since WP20 is the change in the estimate of the leading-order
hadronic-vacuum-polarization (LO HVP) contribution. A new measurement of the
$e^+e^-\to\pi^+\pi^-$ cross section by CMD-3 has increased the tensions among
data-driven dispersive evaluations of the LO HVP contribution to a level that
makes it impossible to combine the results in a meaningful way. At the same
time, the attainable precision of lattice-QCD calculations has increased
substantially and allows for a consolidated lattice-QCD average of the LO HVP
contribution with a precision of about 0.9%. Adopting the latter in this update
has resulted in a major upward shift of the total SM prediction, which now
reads $a_\mu^\text{SM} = 116\,592\,033(62)\times 10^{-11}$ (530 ppb). When
compared against the current experimental average based on the E821 experiment
and runs 1-6 of E989 at Fermilab, one finds $a_\mu^\text{exp} - a_\mu^\text{SM}
=38(63)\times 10^{-11}$, which implies that there is no tension between the SM
and experiment at the current level of precision. The final precision of E989
(127 ppb) is the target of future efforts by the Theory Initiative. The
resolution of the tensions among data-driven dispersive evaluations of the LO
HVP contribution will be a key element in this endeavor.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>188 pages, 83 figures; $a_\mu^\text{exp}$ updated to final result of
  the Fermilab experiment, SM prediction unchanged; journal version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Search for sub-GeV invisible particles in inclusive decays of $J/ψ$
  to $φ$ 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2506.10316v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2506.10316v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A search for an invisible particle, $X$, with a mass between 0 and 0.96
$\textrm{GeV}/\textit{c}^{2}$, is performed in the process
$J/\psi\rightarrow\phi + X$ using $(8774.0\pm39.4)\times10^{6}$ $J/\psi$ events
collected with the BESIII detector from 2017 to 2019. The $\phi$ meson is fully
reconstructed and an efficient veto of photons, neutral and charged hadrons up
to twice the $K_L^0$ mass is applied to the rest of the event and the recoil
mass against the $\phi$ is obtained precisely from the kinematic constraint in
the event. No significant signal over the expected background is observed in
the investigated region and the upper limit on the inclusive branching fraction
of $J/\psi\rightarrow\phi + X$ is determined to be $7.0\times10^{-8}$ at 90\%
confidence level. Upper limits at a 90\% confidence level are also given for
this branching fraction as a function of the invisible particle mass, varying
from $4\times10^{-9}$ to $4\times10^{-8}$ over the investigated mass range.
Additionally, a 90\% confidence level upper limit on the branching fraction of
$\eta\rightarrow \rm{invisible}$ is determined to $2.4\times10^{-5}$, which
improves the previous best results by more than four times. The analysis
technique in this work offers a clean window to search for sub-GeV invisible
particles, which can be adapted for other $J/\psi$ decays and direct $e^+e^-$
annihilation experiments in future studies, and improve the sensitivity by
orders of magnitude.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Fast Stochastic Matching Pursuit for Neutrino and Dark Matter
  Experiments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03156v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03156v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyi Wang, Aiqiang Zhang, Yiyang Wu, Benda Xu, Xuewei Liu, Jiajie Chen, Zhe Wang, Shaomin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Photomultiplier tubes (PMTs) are widely deployed at neutrino and dark matter
experiments for photon counting. When multiple photons hit a PMT consecutively,
their photo-electron (PE) pulses pile up to hinder the precise measurements of
the count and timings. We introduce Fast Stochastic Matching Pursuit (FSMP) to
analyze the PMT signal waveforms into individual PEs with the strategy of
reversible-jump Markov-chain Monte Carlo. We demonstrate that FSMP improves the
energy and time resolution of PMT-based experiments and gains acceleration on
GPUs. It is suitable for dynode PMTs, and is extensible to microchannel-plate
(MCP) PMTs. In the condition of our laboratory characterization of 8-inch
MCP-PMTs, FSMP improves the energy resolution by up to 10% from the
conventional method of waveform integration.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        High Energy Physics - Phenomenology
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cosmic $τ$ensions Indirectly Correlate with Reionization Optical
  Depth 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09678v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09678v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Itamar J. Allali, Lingfeng Li, Praniti Singh, JiJi Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The reionization optical depth $\tau_{\rm reio}$ has interesting connections
to existing cosmological anomalies. As first studied in the context of the
Hubble tension in our previous paper, a larger $\tau_{\rm reio}$, which could
be achieved by removing the Planck low-$\ell$ polarization data, could boost
$H_0$ slightly, resulting in a mild reduction of the tension between the early-
and late-universe determinations of $H_0$. It has been shown later that a
larger $\tau_{\rm reio}$ could also relieve other anomalies including: the
tension between BAO and CMB data, the neutrino mass tension, and the latest
DESI plus supernovae data's tension with the standard cosmological constant
scenario. In this paper, we systematically analyze the correlations between
$\tau_{\rm reio}$ and relevant cosmological parameters in the existing cosmic
observation anomalies. In addition to Pearson correlation coefficients
extracted directly from the covariance matrix, we also study partial
correlation coefficients which measure intrinsic relationships between pairs of
parameters removing the influence of other parameters. We show that $\tau_{\rm
reio}$ has weak intrinsic correlations with the parameters responsible for the
tensions and anomalies discussed. The large direct Pearson correlations that
allow larger $\tau_{\rm reio}$ inferences to alleviate the cosmological
tensions each arise from complicated networks through multiple parameters. As a
result, the relationships between $\tau_{\rm reio}$ and each anomaly are not
independent of each other. We also employ our method of computing correlations
to clarify the impact of large scale polarization data, and comment also on the
effects of CMB observations from ACT and SPT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures, 4 tables, plus appendices</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ultralight Boson Ionization from Comparable-Mass Binary Black Holes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09643v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09643v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Guo, Zhen Zhong, Yifan Chen, Vitor Cardoso, Taishi Ikeda, Lihang Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ultralight bosons around comparable-mass binaries can form gravitationally
bound states analogous to molecules once the binary separation decreases below
the boson's Bohr radius, with the inner region co-moving with the binary. We
simulate the formation of these gravitational molecules, determine their
co-moving regions, and compute ionization fluxes induced by orbital motion for
various binary eccentricities. We develop semi-analytic formalisms to describe
the ionization dynamics of both the co-moving and non-co-moving regions,
demonstrating consistency with numerical simulation results. From ionization
fluxes, we estimate their backreaction on binary orbital evolution. At early
stages, molecule ionization can dominate over gravitational wave emission,
producing a spectral turnover in the gravitational wave background.
Additionally, ionization of the co-moving component occurs solely due to binary
eccentricity, causing orbital circularization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 5 figures, movie:
  https://www.bilibili.com/video/BV1yXHYzrE24/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Electron and Photon Structure Functions at Two Loops 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marvin Schnubel, Robert Szafron
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a fully analytic computation of the complete electron and photon
structure functions, or QED lepton parton distribution functions (PDFs) up to
two-loop order. Our computation is performed using modern techniques of
reduction to Master Integrals and solving them with the differential equation
method. We obtain explicit expressions for the electron-in-electron,
positron-in-electron, photon-in-electron, electron-in-photon, and
photon-in-photon distributions at next-to-next-to-leading order (NNLO).
Cross-checks against one-loop results, existing two-loop calculations, and a
recent soft-collinear effective theory (SCET) analysis of the electron
structure functions are presented.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Constraints on Ultra-heavy DM from TeV-PeV gamma-ray diffuse
  measurements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Rocamora, Pedro De La Torre Luque, Miguel A. Sánchez-Conde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent experiments have measured the Galactic $\gamma$-ray diffuse emission
up to PeV energies, opening a window to study acceleration of Galactic cosmic
rays and their propagation up to the cosmic-ray knee. Furthermore, these
observations provide a powerful tool to set strong constraints into very-heavy
dark matter particles, with masses in the TeV-PeV range. In this paper, we
explore the potential of the newest observations of diffuse emissions at the
Galactic plane from HAWC and LHAASO to probe this kind of dark matter over a
wide mass range. Here, we model secondary emissions (inverse-Compton) from the
electrons and positrons produced in the annihilation/decay of dark matter, on
top of their prompt $\gamma$-ray emission, including the effects of absorption
of high-energy photons via pair production. Furthermore, we show that including
the astrophysical backgrounds (namely diffuse emission from cosmic-ray
collisions or emission from unresolved sources) can significantly improve these
limits. We find that the new measurements provided, specially by LHAASO with
the combination of the WCDA and KM2A detectors, allow us to set strong
constraints in decaying dark matter, being competitive and even improving the
strongest constraints at the moment. We also highlight that these regions lead
to constraints that are less affected by uncertainties from the dark matter
distribution and discuss how CTA north and SWGO will be able to improve limits
in this mass range.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages main text, with 8 figures and appendix with 4 figures.
  Comments are welcome!</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $CP$ asymmetries in the $Λ_c^+\to pK^0_S$ and $Ξ^+_c\to
  Σ^+K^0_S$ decays 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09503v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09503v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Di Wang, Si-Jia Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  $CP$ asymmetry is a crucial element in interpreting the matter-antimatter
asymmetry in the universe and searching for new physics beyond the Standard
Model. In this work, we study the $CP$ asymmetries in the $\Lambda_c^+\to
pK^0_S$ and $\Xi^+_c\to \Sigma^+K^0_S$ decays. The time-independent and
time-integrated $\Gamma$-, $\alpha$-, $\beta$-, and $\gamma$-defined $CP$
asymmetries in the chain decay $\mathcal{B}_{c\overline 3}\to
\mathcal{B}K(t)(\to \pi^{+}\pi^{-})$ are derived. It is found that the $CP$
asymmetry in $K^0-\overline K^0$ mixing cancels out in the $\alpha$-, $\beta$-,
and $\gamma$-defined $CP$ asymmetries. The $U$-spin analysis shows that the
amplitudes of the $\Lambda_c^+\to pK^0$, $\Lambda_c^+\to p\overline K^0$,
$\Xi^+_c\to \Sigma^+ K^0$, and $\Xi^+_c\to \Sigma^+ \overline K^0$ modes are
not independent. The hadronic parameters determining $CP$ asymmetries in the
$\Lambda_c^+\to pK^0_S$ and $\Xi^+_c\to \Sigma^+K^0_S$ decays could be
extracted from the $K^0_S-K^0_L$ asymmetry and decay parameters $\alpha$,
$\beta$, and $\gamma$ in these two decay modes. We find the $CP$-violating
effect induced by the interference between charmed hadron decay and neutral
kaon mixing in the $\Xi^+_c\to \Sigma^+ K^0_S$ decay could reach to be
$\mathcal{O}(10^{-3})$, which is several times larger than those in $D$ meson
decays and at the same order as the $CP$ asymmetry in $K^0-\overline K^0$
mixing. In contrast, the same term in the $\Lambda_c^+\to pK^0_S$ mode are one
order of magnitude smaller. Thus, the $\Xi^+_c\to \Sigma^+ K^0_S$ decay is a
promising mode for observing $CP$ asymmetry in the charmed hadron sector and
verifying the $CP$-violating effect induced by the interference between charm
decay and neutral kaon mixing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Axion-Photon Conversion in FLRW with Primordial Magnetic Fields:
  Explaining the Radio Excess 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09472v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09472v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Setabuddin, Md Riajul Haque, Rajesh Karmakar, Supratik Pal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the possibility of axion-photon conversion as a common origin of
two low-frequency anomalies: the isotropic radio excess (ARCADE2) and the deep
global 21-cm absorption trough (EDGES). From the axion-photon action in an FLRW
background with primordial magnetic fields (PMFs), we derive the
scale-dependent conversion probability including plasma effects. Resonant
conversion, arising when the axion mass matches the plasma-induced photon mass,
produces soft photons in the MHz-GHz range. By modeling stochastic PMFs with
amplitude $B_0$ and spectral index $n_{\rm B}$, we show that axion-like
particles with mass $\sim 10^{-14}$-$10^{-12}\,\mathrm{eV}$ and nanogauss-level
nearly scale invariant PMFs can explain both ARCADE2 and EDGES. Heating from
PMF dissipation via ambipolar diffusion and turbulent decay reduces the 21-cm
trough, shifting the viable parameter space. Our results stem from a consistent
theoretical framework developed from first principles and a combined analysis
of the radio excess and global 21-cm signal, while remaining consistent with
CMB bounds on PMFs and $\Delta N_{\rm eff}$. We conclude that global 21-cm
observations may offer potential sensitivity to axions, primordial magnetism,
and dark-sector physics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 8 figures, 1 table. Comments are welcome</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Casimir scaling in glueballs in SU($N$) and Sp($2N$) gauge theories:
  hints from constituent approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09454v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09454v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        F. Buisseret, C. Chevalier, V. Mathieu, C. Semay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We show that the lattice glueball masses $M_G$ versus $N$ in SU($N$) and
Sp($2N$) Yang-Mills theories scale as $\frac{M_G}{\sqrt\sigma}\sim
\sqrt{\frac{C_2(adj)}{C_2(f)}}$, with $\sigma$ the fundamental string tension
and $C_2(adj)$ and $C_2(f)$ the quadratic Casimir of the gauge algebra in the
adjoint and fundamental representations. This scaling behaviour is followed by
the great majority of available lattice glueball states, and may set
constraints on $SU(3)$ models by imposing a specific behaviour at $N\neq 3$.
The observed scaling is compatible with two assumptions: (1) The glueball
masses are proportional to the square root of the adjoint string tension,
$M_G\sim \sqrt\sigma_{adj}$; (2) The string tension follows the Casimir
scaling, i.e. $\sigma_{adj}=\frac{C_2(adj)}{C_2(f)}\sigma$. In a constituent
gluon picture, our results suggest a low-lying glueball spectrum made of two
transverse constituent gluons bound by an adjoint string, completed by three
transverse constituent gluons bound by a Y-junction of adjoint strings rather
than a $\Delta-$shaped junction of fundamental strings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dark Vector Boson Bremsstrahlung: New Form Factors for a Broader Class
  of Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09437v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09437v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix Kling, Peter Reimitz, Adam Ritz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the sensitivity of collider experiments to a broad class of
GeV-scale dark vector models of new physics via production in proton and
neutron bremsstrahlung and initial state radiation. This is achieved using a
new physically motivated model for timelike vector form factors with generic
charges for both protons and neutrons, which is fit to a variety of timelike
and spacelike data with quantified uncertainties. The production model for both
proton and neutron bremsstrahlung is applied to re-cast and extend the reach of
existing FASER data to GeV-mass dark photons, $U(1)_B$, $U(1)_{B-L}$, and
photophobic vectors, as well as forecasts for millicharged particles at
FORMOSA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tree-level NLO corrections to inclusive $ψ'$ production in High
  Energy Factorization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        A. A. Prokhorov, S. P. Baranov, A. V. Lipatov, M. A. Malyshev, X. Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider inclusive $\psi(2S)$ production in proton-proton collisions at
collider energies in the framework of non-relativistic QCD and high-energy
factorization beyond the low-order approximation. We utilise a matching scheme
proposed earlier to merge the leading order and tree-level next-to-leading
order production amplitudes and now extend it to low transverse momenta and/or
forward rapidities. With the improved scheme, we examine the possibility to
simultaneously describe all unpolarized LHC data in the full kinematic range
accessible to experimental measurements and try different Transverse Momentum
Dependent (TMD) gluon distributions in the proton. A global fit to the data is
carried out to extract the color octet long-distance matrix elements for
$\psi(2S)$ mesons. We show that taking the NLO corrections into account leads
to better description of the data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Toward precise $ξ$ gauge fixing for the lattice QCD 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li-Jun Zhou, Dian-Jun Zhao, Wei-jie Fu, Chun-Jiang Shi, Ji-Hao Wang, Yi-Bo Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Lattice QCD provides a first-principles framework for solving Quantum
Chromodynamics (QCD). However, its application to off-shell partons has been
largely restricted to the Landau gauge, as achieving high-precision $\xi$-gauge
fixing on the lattice poses significant challenges. Motivated by a universal
power-law dependence of off-shell parton matrix elements on gauge-fixing
precision in the Landau gauge, we propose an empirical precision extrapolation
method to approximate high-precision $\xi$-gauge fixing. By properly defining
the bare gauge coupling and then the effective $\xi$, we validate our
$\xi$-gauge fixing procedure by successfully reproducing the $\xi$-dependent
RI/MOM renormalization constants for local quark bilinear operators at 0.2\%
level, up to $\xi \sim 1$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Two-component Dark Matter and low scale Thermal Leptogenesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.21202v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.21202v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subhaditya Bhattacharya, Devabrat Mahanta, Niloy Mondal, Dipankar Pradhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The observable cosmos exhibits sizable baryon asymmetry, small active
neutrino masses, and the presence of dark matter (DM). To address these
phenomena together, we propose a two component DM scenario in an extension of
Scotogenic model, imposing $\mathbb{Z}_2 \otimes \mathbb{Z}_2^{\prime}$
symmetry. The electroweak sphaleron process converts the $\rm Y_{B-L}^{}$
yield, generated through the Leptogenesis mechanism, into the baryon asymmetry
($\rm Y_{\Delta B}^{}$) at $\rm T_{\rm sph}\sim 130$ GeV, the sphalerons
decoupling temperature. In this framework, the CP asymmetry as well as the
radiative neutrino mass generation explicitly involve the two DM particles,
thus establishing a correlation between the baryon asymmetry, DM and observed
active neutrino masses. We study in details the allowed parameter space
available after considering all the constraints from the three phenomena as
well as from the collider search limits, and outline the region which could
potentially be tested in future DM detection experiments through direct or
indirect detection searches, lepton flavor-violating decays, etc.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Precision $e^+e^-$ Hemisphere Masses in the Di<span class="highlight-title">jet</span> Region with Power
  Corrections 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2506.09130v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2506.09130v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andre H. Hoang, Vicent Mateu, Matthew D. Schwartz, Iain W. Stewart
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We derive high-precision results for the $e^+e^-$ heavy jet mass (HJM) $d
\sigma/d \rho$ and dihemisphere mass (DHM) $d^2\sigma/(d s_1 d s_2)$
distributions, for $s_1\sim s_2$, in the dijet region. New results include: i)
the N$^3$LL resummation for HJM of large logarithms $\ln^n(\rho)$ at small
$\rho$ including the exact two-loop non-global hemisphere soft function, the
4-loop cusp anomalous dimension and the 3-loop hard and jet functions, ii)
N$^3$LL results for DHM with resummation of logarithms $\ln(s_{1,2}/Q^2)$ when
there is no large separation between $s_1$ and $s_2$, iii) profile functions
for HJM to give results simultaneously valid in the peak and tail regions, iv)
a complete two-dimensional basis of non-perturbative functions which can be
used for double differential observables, that are needed for both HJM and DHM
in the peak region, and v) an implementation of renormalon subtractions for
large-angle soft radiation to ${\cal O}(\alpha_s^3)$ together with a
resummation of the additional large $\ln(Q\rho/\Lambda_{QCD})$ logarithms. Here
$Q$ is the $e^+e^-$ center-of-mass energy. Our resummation results are combined
with known fixed-order ${\cal O}(\alpha_s^3)$ results and we discuss the
convergence and remaining perturbative uncertainty in the cross section. We
also prove that, at order $1/Q$, the first moment of the HJM distribution
involves an additional non-perturbative parameter compared to the power
correction that shifts the tail of the spectrum (where $1\gg \rho\gg
\Lambda_{QCD}/Q$). This differs from thrust where a single non-perturbative
parameter at order $1/Q$ describes both the first moment and the tail, and it
disfavors models of power corrections employing a single non-perturbative
parameter, such as the low-scale effective coupling model. In this paper we
focus only on the dijet region, not the far-tail distribution for $\rho \gtrsim
0.2$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 12 figures, published version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring two component doublet dark matter 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.02816v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.02816v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mariana Frank, Purusottam Ghosh, Chayan Majumdar, Supriya Senapati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a two-component dark matter (DM) scenario by extending the
Standard Model with two additional $SU(2)_L$ doublets, one scalar, and another
fermion. To ensure the stability of the DM components, we impose a global $Z_2
\times Z_2^\prime$ symmetry. The lightest neutral states for both the scalar
and fermion, which are non-trivially transformed under the extended symmetry,
behave as stable two-component DM candidates. While single components are
under-abundant due to their gauge interactions, in a mass region between $m_W$
and $525$ GeV for the scalar and a mass below $1200$ GeV for the fermion, and
the fermion DM conflicts with direct detection limits over the whole parameter
space, having two components helps to saturate relic density in the regions
with under-abundance. Compliance with direct detection constraints leads to two
options, either introducing dim-5 effective operators, or embedding the
scenarios into a complete UV theory, which reproduces a type II seesaw model,
thus naturally including neutrino masses. We analyze the consequences of this
scenario at the LHC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 26 figures, 4 tables, Matches the published version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Thermodynamic and quantum fluctuations of horizon area 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.08006v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.08006v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        G. E. Volovik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The event horizon is a source of irreversibility, analogous to statistical
irreversibility. This is why for systems with an event horizon there is no
difference between quantum and thermal fluctuations. Quantum processes of
quantum tunneling determine the thermodynamics of these systems, their
temperatures, entropies and fluctuations. We considered three examples of
entropy variance that support this point of view: (i) the variance of the area
of the black hole horizon, obtained by consideration of quantum fluctuations;
(ii) the variance of the entropy of the Hubble volume in the de Sitter state,
obtained by consideration of thermal fluctuations; and (iii) the variance of
entropy in integers in the Planckon model, determined by the Poisson
distribution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, no figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do QGP Droplets Drive Anisotropy in Small Systems? Insights from RHIC
  and the LHC 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.21183v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.21183v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roy A. Lacey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Azimuthal anisotropy scaling functions for identified mesons and baryons are
analyzed in large (Pb+Pb at $\sqrt{s_{NN}} = 2.76$ and 5.02 TeV, Au+Au at
$\sqrt{s_{NN}} = 200$ GeV), intermediate (Cu+Cu at $\sqrt{s_{NN}} = 200$~GeV),
and small (p+Pb at $\sqrt{s_{NN}} = 5.02$ and 8.16 TeV, p+Au, d+Au, and
$^3$He+Au at $\sqrt{s_{NN}} = 200$ GeV) collision systems. The scaling
functions' fidelity supports a hydrodynamic-like origin for anisotropies in the
flow-dominated regime. Central Pb+Pb, Au+Au, and Cu+Cu reflect QGP-driven
expansion with strong radial flow and significant jet quenching, while
peripheral Pb+Pb and Cu+Cu exhibit hadronic-dominated dynamics. In contrast,
central RHIC small systems show hadronic-dominated behavior, with strong
re-scattering, negligible radial flow, and suppressed jet quenching, following
the hierarchy p+Au $>$ d+Au $>$ $^3$He+Au. At the LHC, ultra-central p+Pb
collisions display enhanced radial flow, reduced re-scattering, and small but
nonzero jet quenching. Scaling violations at high $p_T$ reflect partial
suppression of partonic energy loss. These findings demonstrate that QGP-like
behavior in small systems depends sensitively on both system size and beam
energy, and establish the scaling framework as a robust diagnostic of
collectivity and medium properties across diverse collision conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Seven pages, four figures, submitted for publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Holographic <span class="highlight-title">quark</span> masses and radiative decays of heavy vector <span class="highlight-title">meson</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.14324v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.14324v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saulo Diles, Miguel Angel Martin Contreras, Alfredo Vega
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Holographic models of QCD provide the spectrum of heavy vector meson masses
and electromagnetic decay constants through bulk computations of the
current-current correlation function. Conversely, the phenomenology of heavy
vector mesons is articulated by the constituent heavy quark model utilizing a
non-relativistic approximation. By applying the Segre formula from
non-relativistic quantum mechanics, we derive new observables from holography:
the constituent quark mass, the three-photon decay width, the effective fine
structure constant of the strong interaction, and the mixed one-photon and
two-gluon decay width. We also derive the three-gluon decay width, the
three-photon decay width, and the mixed one-photon and two-gluon decay width
for the radially excited states of heavy quarkonia and compare them with
available experimental data. The present results reveal a new paradigm of meson
spectroscopy in AdS/QCD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Physics consistent machine learning framework for inverse modeling with
  applications to ICF capsule implosions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.20192v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.20192v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel A. Serino, Evan Bell, Marc Klasky, Ben S. Southworth, Balasubramanya Nadiga, Trevor Wilcox, Oleg Korobkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In high energy density physics (HEDP) and inertial confinement fusion (ICF),
predictive modeling is complicated by uncertainty in parameters that
characterize various aspects of the modeled system, such as those
characterizing material properties, equation of state (EOS), opacities, and
initial conditions. Typically, however, these parameters are not directly
observable. What is observed instead is a time sequence of radiographic
projections using X-rays. In this work, we define a set of sparse hydrodynamic
features derived from the outgoing shock profile and outer material edge, which
can be obtained from radiographic measurements, to directly infer such
parameters. Our machine learning (ML)-based methodology involves a pipeline of
two architectures, a radiograph-to-features network (R2FNet) and a
features-to-parameters network (F2PNet), that are trained independently and
later combined to approximate a posterior distribution for the parameters from
radiographs. We show that the estimated parameters can be used in a
hydrodynamics code to obtain density fields and hydrodynamic shock and outer
edge features that are consistent with the data. Finally, we demonstrate that
features resulting from an unknown EOS model can be successfully mapped onto
parameters of a chosen analytical EOS model, implying that network predictions
are learning physics, with a degree of invariance to the underlying choice of
EOS model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Early Career Researcher Input to the European Strategy for Particle
  Physics Update: White Paper 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.19862v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.19862v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan-Hendrik Arling, Alexander Burgman, Christina Dimitriadi, Ulrich Einhaus, Axel Gallén, Abdelhamid Haddad, Laura Huhta, Armin Ilg, Jan Klamka, Elizabeth Long, Thomas Madlener, Arnau Morancho Tardà, Emanuela Musumeci, Krzysztof Mękała, Elena Pompa Pacchi, Marvin Pfaff, Daniel Reichelt, Leonhard Reichenbach, Birgit Stapf, Francesco P. Ucci, Erik Wallin, Harriet Watson, Sagar Vidya Addepalli, Bruno Alves, Robert Mihai Amarinei, Ricardo Barrué, Lydia Brenner, Giacomo Da Molin, Arturo de Giorgi, Bohdan Dudar, Francesco Giuli, Andrea Gurgone, César Jesús-Valls, Antoine Laudrain, Martin J. Losekamm, Rafał Masełek, Wrishik Naskar, Miquel Nebot-Guinot, Marko Pesut, Thomas Pöschl, Efrain P. Segarra, Rebecca Taylor, Pavel Vana, Hannah Wakeling, Aidan R. Wiederhold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This document, written by early career researchers (ECRs) in particle
physics, aims to represent the perspectives of the European ECR community and
serves as input for the 2025--2026 update of the European Strategy for Particle
Physics. With input from a community-wide survey, it highlights key challenges
faced by ECRs -- career stability, funding access and long-term research
opportunities -- while proposing policy recommendations and targeted
initiatives. It underscores the importance of practices fostering diverse,
equitable, inclusive and healthy workplaces, as well as of stronger ECR
communities, and highlights how effective communication and interdisciplinary
collaborations reinforce the societal relevance of particle physics and promote
continued support for large-scale and long-term projects. Finally, the future
of both collider and beyond-collider experiments is addressed, emphasising the
critical role of ECRs in shaping future projects. The ECR contribution is
formed of two parts: the ten-page executive summary submitted as input to the
European Strategy for Particle Physics Update and, as backup document, this
extended white paper providing additional context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Endorsed by the ECFA ECR Panel. Editor and author attribution in the
  document</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On multi-propagator angular integrals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.00693v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.00693v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juliane Haug, Vladimir A. Smirnov, Fabian Wunder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study multi-propagator angular integrals, a class of phase-space integrals
relevant to processes with multiple observed final states and a test-bed for
transferring loop-integral technology to phase space integrals without reversed
unitarity. We present an Euler integral representation similar to
Lee-Pomeransky representation and explicitly describe a recursive IBP reduction
and dimensional shift relations for the general case of $n$ denominators. On
the level of master integrals, applying a differential equation approach, we
explicitly calculate the previously unknown angular integrals with four
denominators for any number of masses to finite order in $\varepsilon$.
Extending the idea of dimensional recurrence, we explore the decomposition of
angular integrals into branch integrals reducing the number of scales in the
master integrals from $(n+1)n/2$ to $n+1$. To showcase the potential of this
method, we calculate the massless three denominator integral to establish
all-order results in $\varepsilon$ including a resummation of soft logarithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Searching for Particle Dark Matter with eROSITA Early Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.16747v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.16747v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chingam Fong, Kenny C. Y. Ng, Qishan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many well motivated dark matter (DM) particle candidates can decay into
detectable X-ray photons. We analyze the Final Equatorial Depth Survey (eFEDS)
data from eROSITA early data release to search for unidentified X-ray lines
that could indicate DM signals. Having discovered no anomalous signal, we set
limits on DM decay rate in mass range between 1.8-18 keV, and constrain the
parameter space of two DM particles: sterile neutrino and axion-like particles.
Finally we also study the projected sensitivity of eROSITA full sky search,
showing that eROSITA all-sky survey is expected to set the most stringent
limits in the soft X-ray band.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12+3 pages, 7+2 figures. v3 updated to match version accepted by PRD:
  redone GC and all-sky projection; added appendix B checking different diffuse
  sky models; added details and fixed typos; results & conlusions unchanged</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning - Statistics
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Expressive Power of Deep Networks on Manifolds: Simultaneous
  Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanfei Zhou, Lei Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A key challenge in scientific machine learning is solving partial
differential equations (PDEs) on complex domains, where the curved geometry
complicates the approximation of functions and their derivatives required by
differential operators. This paper establishes the first simultaneous
approximation theory for deep neural networks on manifolds. We prove that a
constant-depth $\mathrm{ReLU}^{k-1}$ network with bounded weights--a property
that plays a crucial role in controlling generalization error--can approximate
any function in the Sobolev space $\mathcal{W}_p^{k}(\mathcal{M}^d)$ to an
error of $\varepsilon$ in the $\mathcal{W}_p^{s}(\mathcal{M}^d)$ norm, for
$k\geq 3$ and $s<k$, using $\mathcal{O}(\varepsilon^{-d/(k-s)})$ nonzero
parameters, a rate that overcomes the curse of dimensionality by depending only
on the intrinsic dimension $d$. These results readily extend to functions in
H\"older-Zygmund spaces. We complement this result with a matching lower bound,
proving our construction is nearly optimal by showing the required number of
parameters matches up to a logarithmic factor. Our proof of the lower bound
introduces novel estimates for the Vapnik-Chervonenkis dimension and
pseudo-dimension of the network's high-order derivative classes. These
complexity bounds provide a theoretical cornerstone for learning PDEs on
manifolds involving derivatives. Our analysis reveals that the network
architecture leverages a sparse structure to efficiently exploit the manifold's
low-dimensional geometry.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-degree lower bounds via almost orthonormal bases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09353v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09353v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandra Carpentier, Simone Maria Giancola, Christophe Giraud, Nicolas Verzelen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-degree polynomials have emerged as a powerful paradigm for providing
evidence of statistical-computational gaps across a variety of high-dimensional
statistical models [Wein25]. For detection problems -- where the goal is to
test a planted distribution $\mathbb{P}'$ against a null distribution
$\mathbb{P}$ with independent components -- the standard approach is to bound
the advantage using an $\mathbb{L}^2(\mathbb{P})$-orthonormal family of
polynomials. However, this method breaks down for estimation tasks or more
complex testing problems where $\mathbb{P}$ has some planted structures, so
that no simple $\mathbb{L}^2(\mathbb{P})$-orthogonal polynomial family is
available. To address this challenge, several technical workarounds have been
proposed [SW22,SW25], though their implementation can be delicate. In this
work, we propose a more direct proof strategy. Focusing on random graph models,
we construct a basis of polynomials that is almost orthonormal under
$\mathbb{P}$, in precisely those regimes where statistical-computational gaps
arise. This almost orthonormal basis not only yields a direct route to
establishing low-degree lower bounds, but also allows us to explicitly identify
the polynomials that optimize the low-degree criterion. This, in turn, provides
insights into the design of optimal polynomial-time algorithms. We illustrate
the effectiveness of our approach by recovering known low-degree lower bounds,
and establishing new ones for problems such as hidden subcliques, stochastic
block models, and seriation models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Global Optimization of Stochastic Black-Box Functions with Arbitrary
  Noise Distributions using Wilson Score Kernel Density Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09238v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09238v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thorbjørn Mosekjær Iversen, Lars Carøe Sørensen, Simon Faarvang Mathiesen, Henrik Gordon Petersen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many optimization problems in robotics involve the optimization of
time-expensive black-box functions, such as those involving complex simulations
or evaluation of real-world experiments. Furthermore, these functions are often
stochastic as repeated experiments are subject to unmeasurable disturbances.
Bayesian optimization can be used to optimize such methods in an efficient
manner by deploying a probabilistic function estimator to estimate with a given
confidence so that regions of the search space can be pruned away.
Consequently, the success of the Bayesian optimization depends on the function
estimator's ability to provide informative confidence bounds. Existing function
estimators require many function evaluations to infer the underlying confidence
or depend on modeling of the disturbances. In this paper, it is shown that the
confidence bounds provided by the Wilson Score Kernel Density Estimator
(WS-KDE) are applicable as excellent bounds to any stochastic function with an
output confined to the closed interval [0;1] regardless of the distribution of
the output. This finding opens up the use of WS-KDE for stable global
optimization on a wider range of cost functions. The properties of WS-KDE in
the context of Bayesian optimization are demonstrated in simulation and applied
to the problem of automated trap design for vibrational part feeders.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable extensions to given-data Sobol' index estimators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teresa Portone, Bert Debusschere, Samantha Yang, Emiliano Islas-Quinones, T. Patrick Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given-data methods for variance-based sensitivity analysis have significantly
advanced the feasibility of Sobol' index computation for computationally
expensive models and models with many inputs. However, the limitations of
existing methods still preclude their application to models with an extremely
large number of inputs. In this work, we present practical extensions to the
existing given-data Sobol' index method, which allow variance-based sensitivity
analysis to be efficiently performed on large models such as neural networks,
which have $>10^4$ parameterizable inputs. For models of this size, holding all
input-output evaluations simultaneously in memory -- as required by existing
methods -- can quickly become impractical. These extensions also support
nonstandard input distributions with many repeated values, which are not
amenable to equiprobable partitions employed by existing given-data methods.
  Our extensions include a general definition of the given-data Sobol' index
estimator with arbitrary partition, a streaming algorithm to process
input-output samples in batches, and a heuristic to filter out small indices
that are indistinguishable from zero indices due to statistical noise. We show
that the equiprobable partition employed in existing given-data methods can
introduce significant bias into Sobol' index estimates even at large sample
sizes and provide numerical analyses that demonstrate why this can occur. We
also show that our streaming algorithm can achieve comparable accuracy and
runtimes with lower memory requirements, relative to current methods which
process all samples at once. We demonstrate our novel developments on two
application problems in neural network modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STRIDE: Scalable and Interpretable XAI via Subset-Free Functional
  Decomposition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09070v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09070v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaeyun Ko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most explainable AI (XAI) frameworks face two practical limitations: the
exponential cost of reasoning over feature subsets and the reduced
expressiveness of summarizing effects as single scalar values. We present
STRIDE, a scalable framework that aims to mitigate both issues by framing
explanation as a subset-enumeration-free, orthogonal functional decomposition
in a Reproducing Kernel Hilbert Space (RKHS). Rather than focusing only on
scalar attributions, STRIDE computes functional components f_S(x_S) via an
analytical projection scheme based on a recursive kernel-centering procedure,
avoiding explicit subset enumeration. In the tabular setups we study, the
approach is model-agnostic, provides both local and global views, and is
supported by theoretical results on orthogonality and L^2 convergence under
stated assumptions. On public tabular benchmarks in our environment, we
observed speedups ranging from 0.6 times (slower than TreeSHAP on a small
dataset) to 9.7 times (California), with a median approximate 3.0 times across
10 datasets, while maintaining high fidelity (R^2 between 0.81 and 0.999) and
substantial rank agreement on most datasets. Overall, STRIDE complements scalar
attribution methods by offering a structured functional perspective, enabling
novel diagnostics like 'component surgery' to quantitatively measure the impact
of specific interactions within our experimental scope.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Average Causal Effect Estimation in DAGs with Hidden Variables: Beyond
  Back-Door and Front-Door Criteria 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03962v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03962v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Guo, Razieh Nabi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The identification theory for causal effects in directed acyclic graphs
(DAGs) with hidden variables is well established, but methods for estimating
and inferring functionals that extend beyond the g-formula remain
underdeveloped. Previous studies have introduced semiparametric estimators for
such functionals in a broad class of DAGs with hidden variables. While these
estimators exhibit desirable statistical properties such as double robustness
in certain cases, they also face significant limitations. Notably, they
encounter substantial computational challenges, particularly involving density
estimation and numerical integration for continuous variables, and their
estimates may fall outside the parameter space of the target estimand.
Additionally, the asymptotic properties of these estimators is underexplored,
especially when integrating flexible statistical and machine learning models
for nuisance functional estimations. This paper addresses these challenges by
introducing novel one-step corrected plug-in and targeted minimum loss-based
estimators of causal effects for a class of hidden variable DAGs that go beyond
classical back-door and front-door criteria (known as the treatment primal
fixability criterion in prior literature). These estimators leverage
data-adaptive machine learning algorithms to minimize modeling assumptions
while ensuring key statistical properties including double robustness,
efficiency, boundedness within the target parameter space, and asymptotic
linearity under $L^2(P)$-rate conditions for nuisance functional estimates that
yield root-n consistent causal effect estimates. To ensure our estimation
methods are accessible in practice, we provide the flexCausal package in R.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Euclidean Distance Deflation Under High-Dimensional Heteroskedastic
  Noise 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2507.18520v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2507.18520v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keyi Li, Yuval Kluger, Boris Landa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pairwise Euclidean distance calculation is a fundamental step in many machine
learning and data analysis algorithms. In real-world applications, however,
these distances are frequently distorted by heteroskedastic
noise$\unicode{x2014}$a prevalent form of inhomogeneous corruption
characterized by variable noise magnitudes across data observations. Such noise
inflates the computed distances in a nontrivial way, leading to
misrepresentations of the underlying data geometry. In this work, we address
the tasks of estimating the noise magnitudes per observation and correcting the
pairwise Euclidean distances under heteroskedastic noise. Perhaps surprisingly,
we show that in general high-dimensional settings and without assuming prior
knowledge on the clean data structure or noise distribution, both tasks can be
performed reliably, even when the noise levels vary considerably. Specifically,
we develop a principled, hyperparameter-free approach that jointly estimates
the noise magnitudes and corrects the distances. We provide theoretical
guarantees for our approach, establishing probabilistic bounds on the
estimation errors of both noise magnitudes and distances. These bounds,
measured in the normalized $\ell_1$ norm, converge to zero at polynomial rates
as both feature dimension and dataset size increase. Experiments on synthetic
datasets demonstrate that our method accurately estimates distances in
challenging regimes, significantly improving the robustness of subsequent
distance-based computations. Notably, when applied to single-cell RNA
sequencing data, our method yields noise magnitude estimates consistent with an
established prototypical model, enabling accurate nearest neighbor
identification that is fundamental to many downstream analyses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Asynchronous Gossip Algorithms for Rank-Based Statistical Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.07543v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.07543v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Van Elst, Igor Colin, Stephan Clémençon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As decentralized AI and edge intelligence become increasingly prevalent,
ensuring robustness and trustworthiness in such distributed settings has become
a critical issue-especially in the presence of corrupted or adversarial data.
Traditional decentralized algorithms are vulnerable to data contamination as
they typically rely on simple statistics (e.g., means or sum), motivating the
need for more robust statistics. In line with recent work on decentralized
estimation of trimmed means and ranks, we develop gossip algorithms for
computing a broad class of rank-based statistics, including L-statistics and
rank statistics-both known for their robustness to outliers. We apply our
method to perform robust distributed two-sample hypothesis testing, introducing
the first gossip algorithm for Wilcoxon rank-sum tests. We provide rigorous
convergence guarantees, including the first convergence rate bound for
asynchronous gossip-based rank estimation. We empirically validate our
theoretical results through experiments on diverse network topologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revisiting Non-Acyclic GFlowNets in Discrete Environments <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07735v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07735v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikita Morozov, Ian Maksimov, Daniil Tiapkin, Sergey Samsonov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative Flow Networks (GFlowNets) are a family of generative models that
learn to sample objects from a given probability distribution, potentially
known up to a normalizing constant. Instead of working in the object space,
GFlowNets proceed by sampling trajectories in an appropriately constructed
directed acyclic graph environment, greatly relying on the acyclicity of the
graph. In our paper, we revisit the theory that relaxes the acyclicity
assumption and present a simpler theoretical framework for non-acyclic
GFlowNets in discrete environments. Moreover, we provide various novel
theoretical insights related to training with fixed backward policies, the
nature of flow functions, and connections between entropy-regularized RL and
non-acyclic GFlowNets, which naturally generalize the respective concepts and
theoretical results from the acyclic setting. In addition, we experimentally
re-examine the concept of loss stability in non-acyclic GFlowNet training, as
well as validate our own theoretical findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2025; minor corrections in proofs of Proposition 3.6 and 3.8 in
  v3, all results remain unchanged</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Information Dynamics of Generative Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.19897v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.19897v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Ambrogioni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative diffusion models have emerged as a powerful class of models in
machine learning, yet a unified theoretical understanding of their operation is
still developing. This paper provides an integrated perspective on generative
diffusion by connecting their dynamic, information-theoretic, and thermodynamic
properties under a unified mathematical framework. We demonstrate that the rate
of conditional entropy production during generation (i.e. the generative
bandwidth) is directly governed by the expected divergence of the score
function's vector field. This divergence, in turn, is linked to the branching
of trajectories and generative bifurcations, which we characterize as
symmetry-breaking phase transitions in the energy landscape. This synthesis
offers a powerful insight: the process of generation is fundamentally driven by
the controlled, noise-induced breaking of (approximate) symmetries, where peaks
in information transfer correspond to critical transitions between possible
outcomes. The score function acts as a dynamic non-linear filter that regulates
the bandwidth of the noise by suppressing fluctuations that are incompatible
with the data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling Multiple Descents in Unsupervised Autoencoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11703v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11703v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kobi Rahimi, Yehonathan Refael, Tom Tirer, Ofir Lindenbaum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The phenomenon of double descent has challenged the traditional bias-variance
trade-off in supervised learning but remains unexplored in unsupervised
learning, with some studies arguing for its absence. In this study, we first
demonstrate analytically that double descent does not occur in linear
unsupervised autoencoders (AEs). In contrast, we show for the first time that
both double and triple descent can be observed with nonlinear AEs across
various data models and architectural designs. We examine the effects of
partial sample and feature noise and highlight the importance of bottleneck
size in influencing the double descent curve. Through extensive experiments on
both synthetic and real datasets, we uncover model-wise, epoch-wise, and
sample-wise double descent across several data types and architectures. Our
findings indicate that over-parameterized models not only improve
reconstruction but also enhance performance in downstream tasks such as anomaly
detection and domain adaptation, highlighting their practical value in complex
real-world scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uniform convergence for Gaussian kernel ridge regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.11274v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.11274v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Dommel, Rajmadan Lakshmanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper establishes the first polynomial convergence rates for Gaussian
kernel ridge regression (KRR) with a fixed hyperparameter in both the uniform
and the $L^{2}$-norm. The uniform convergence result closes a gap in the
theoretical understanding of KRR with the Gaussian kernel, where no such rates
were previously known. In addition, we prove a polynomial $L^{2}$-convergence
rate in the case, where the Gaussian kernel's width parameter is fixed. This
also contributes to the broader understanding of smooth kernels, for which
previously only sub-polynomial $L^{2}$-rates were known in similar settings.
Together, these results provide new theoretical justification for the use of
Gaussian KRR with fixed hyperparameters in nonparametric regression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The submission is being withdrawn because the authorship of the
  manuscript does not comply with the publishing/authorship guidelines of our
  department</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rethinking Disentanglement under Dependent Factors of Variation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07016v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07016v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Almudévar, Alfonso Ortega
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representation learning is an approach that allows to discover and extract
the factors of variation from the data. Intuitively, a representation is said
to be disentangled if it separates the different factors of variation in a way
that is understandable to humans. Definitions of disentanglement and metrics to
measure it usually assume that the factors of variation are independent of each
other. However, this is generally false in the real world, which limits the use
of these definitions and metrics to very specific and unrealistic scenarios. In
this paper we give a definition of disentanglement based on information theory
that is also valid when the factors of variation are not independent.
Furthermore, we relate this definition to the Information Bottleneck Method.
Finally, we propose a method to measure the degree of disentanglement from the
given definition that works when the factors of variation are not independent.
We show through different experiments that the method proposed in this paper
correctly measures disentanglement with non-independent factors of variation,
while other methods fail in this scenario.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Iterative Methods for Full-Scale Gaussian Process Approximations for
  Large Spatial Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14492v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14492v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tim Gyger, Reinhard Furrer, Fabio Sigrist
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gaussian processes are flexible probabilistic regression models which are
widely used in statistics and machine learning. However, a drawback is their
limited scalability to large data sets. To alleviate this, full-scale
approximations (FSAs) combine predictive process methods and covariance
tapering, thus approximating both global and local structures. We show how
iterative methods can be used to reduce computational costs in calculating
likelihoods, gradients, and predictive distributions with FSAs. In particular,
we introduce a novel preconditioner and show theoretically and empirically that
it accelerates the conjugate gradient method's convergence speed and mitigates
its sensitivity with respect to the FSA parameters and the eigenvalue structure
of the original covariance matrix, and we demonstrate empirically that it
outperforms a state-of-the-art pivoted Cholesky preconditioner. Furthermore, we
introduce an accurate and fast way to calculate predictive variances using
stochastic simulation and iterative methods. In addition, we show how our newly
proposed FITC preconditioner can also be used in iterative methods for Vecchia
approximations. In our experiments, it outperforms existing state-of-the-art
preconditioners for Vecchia approximations. All methods are implemented in a
free C++ software library with high-level Python and R packages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Robust Influence Functions with Flat Validation Minima <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.19097v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.19097v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xichen Ye, Yifan Wu, Weizhong Zhang, Cheng Jin, Yifan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Influence Function (IF) is a widely used technique for assessing the
impact of individual training samples on model predictions. However, existing
IF methods often fail to provide reliable influence estimates in deep neural
networks, particularly when applied to noisy training data. This issue does not
stem from inaccuracies in parameter change estimation, which has been the
primary focus of prior research, but rather from deficiencies in loss change
estimation, specifically due to the sharpness of validation risk. In this work,
we establish a theoretical connection between influence estimation error,
validation set risk, and its sharpness, underscoring the importance of flat
validation minima for accurate influence estimation. Furthermore, we introduce
a novel estimation form of Influence Function specifically designed for flat
validation minima. Experimental results across various tasks validate the
superiority of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICML 2025. arXiv admin note: text overlap with
  arXiv:2310.00902 by other authors</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning - Computer Science
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ButterflyQuant: Ultra-low-bit <span class="highlight-title">LLM</span> Quantization through Learnable
  Orthogonal Butterfly Transforms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09679v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09679v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bingxin Xu, Zhen Dong, Oussama Elachqar, Yuzhang Shang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Replace discrete Hadamard transforms with continuous Butterfly
  transforms to facilitate the learning of rotation matrices in LLM
  quantization</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhan Li, Yuxin Zuo, Jiale Yu, Yuhao Zhang, Zhaohui Yang, Kaiyan Zhang, Xuekai Zhu, Yuchen Zhang, Tianxing Chen, Ganqu Cui, Dehui Wang, Dingxiang Luo, Yuchen Fan, Youbang Sun, Jia Zeng, Jiangmiao Pang, Shanghang Zhang, Yu Wang, Yao Mu, Bowen Zhou, Ning Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning
  in <span class="highlight-title">Large Language Model</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runpeng Dai, Linfeng Song, Haolin Liu, Zhenwen Liang, Dian Yu, Haitao Mi, Zhaopeng Tu, Rui Liu, Tong Zheng, Hongtu Zhu, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Steering MoE <span class="highlight-title">LLM</span>s via Expert (De)Activation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09660v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09660v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohsen Fayyaz, Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Ryan Rossi, Trung Bui, Hinrich Schütze, Nanyun Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Feasibility-Guided Fair Adaptive <span class="highlight-title">Offline</span> Reinforcement Learning for
  Medicaid Care Management 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sanjay Basu, Sadiq Y. Patel, Parth Sheth, Bhairavi Muralidharan, Namrata Elamaran, Aakriti Kinra, Rajaie Batniji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning
(FG-FARL), an offline RL procedure that calibrates per-group safety thresholds
to reduce harm while equalizing a chosen fairness target (coverage or harm)
across protected subgroups. Using de-identified longitudinal trajectories from
a Medicaid population health management program, we evaluate FG-FARL against
behavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global
conformal safety baseline). We report off-policy value estimates with bootstrap
95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL
achieves comparable value to baselines while improving fairness metrics,
demonstrating a practical path to safer and more equitable decision support.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval-Augmented Generation for Reliable Interpretation of Radio
  Regulations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09651v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09651v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zakaria El Kassimi, Fares Fourati, Mohamed-Slim Alouini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Functional Groups are All you Need for Chemically Interpretable
  Molecular Property Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roshan Balaji, Joe Bobby, Nirav Pravinbhai Bhatt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular property prediction using deep learning (DL) models has accelerated
drug and materials discovery, but the resulting DL models often lack
interpretability, hindering their adoption by chemists. This work proposes
developing molecule representations using the concept of Functional Groups (FG)
in chemistry. We introduce the Functional Group Representation (FGR) framework,
a novel approach to encoding molecules based on their fundamental chemical
substructures. Our method integrates two types of functional groups: those
curated from established chemical knowledge (FG), and those mined from a large
molecular corpus using sequential pattern mining (MFG). The resulting FGR
framework encodes molecules into a lower-dimensional latent space by leveraging
pre-training on a large dataset of unlabeled molecules. Furthermore, the
proposed framework allows the inclusion of 2D structure-based descriptors of
molecules. We demonstrate that the FGR framework achieves state-of-the-art
performance on a diverse range of 33 benchmark datasets spanning physical
chemistry, biophysics, quantum mechanics, biological activity, and
pharmacokinetics while enabling chemical interpretability. Crucially, the
model's representations are intrinsically aligned with established chemical
principles, allowing chemists to directly link predicted properties to specific
functional groups and facilitating novel insights into structure-property
relationships. Our work presents a significant step toward developing
high-performing, chemically interpretable DL models for molecular discovery.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explaining Concept Drift through the Evolution of Group Counterfactuals 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09616v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09616v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ignacy Stępka, Jerzy Stefanowski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning models in dynamic environments often suffer from concept
drift, where changes in the data distribution degrade performance. While
detecting this drift is a well-studied topic, explaining how and why the
model's decision-making logic changes still remains a significant challenge. In
this paper, we introduce a novel methodology to explain concept drift by
analyzing the temporal evolution of group-based counterfactual explanations
(GCEs). Our approach tracks shifts in the GCEs' cluster centroids and their
associated counterfactual action vectors before and after a drift. These
evolving GCEs act as an interpretable proxy, revealing structural changes in
the model's decision boundary and its underlying rationale. We operationalize
this analysis within a three-layer framework that synergistically combines
insights from the data layer (distributional shifts), the model layer
(prediction disagreement), and our proposed explanation layer. We show that
such holistic view allows for a more comprehensive diagnosis of drift, making
it possible to distinguish between different root causes, such as a spatial
data shift versus a re-labeling of concepts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>TempXAI Workshop @ ECML PKDD 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReBaNO: Reduced Basis <span class="highlight-title">Neural</span> Operator Mitigating Generalization Gaps and
  Achieving Discretization Invariance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haolan Zheng, Yanlai Chen, Jiequn Han, Yue Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel data-lean operator learning algorithm, the Reduced Basis
Neural Operator (ReBaNO), to solve a group of PDEs with multiple distinct
inputs. Inspired by the Reduced Basis Method and the recently introduced
Generative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a
mathematically rigorous greedy algorithm to build its network structure offline
adaptively from the ground up. Knowledge distillation via task-specific
activation function allows ReBaNO to have a compact architecture requiring
minimal computational cost online while embedding physics. In comparison to
state-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO,
and CNO, numerical results demonstrate that ReBaNO significantly outperforms
them in terms of eliminating/shrinking the generalization gap for both in- and
out-of-distribution tests and being the only operator learning algorithm
achieving strict discretization invariance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conditioning on PDE Parameters to Generalise Deep Learning Emulation of
  Stochastic and Chaotic Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09599v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09599v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ira J. S. Shokar, Rich R. Kerswell, Peter H. Haynes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a deep learning emulator for stochastic and chaotic
spatio-temporal systems, explicitly conditioned on the parameter values of the
underlying partial differential equations (PDEs). Our approach involves
pre-training the model on a single parameter domain, followed by fine-tuning on
a smaller, yet diverse dataset, enabling generalisation across a broad range of
parameter values. By incorporating local attention mechanisms, the network is
capable of handling varying domain sizes and resolutions. This enables
computationally efficient pre-training on smaller domains while requiring only
a small additional dataset to learn how to generalise to larger domain sizes.
We demonstrate the model's capabilities on the chaotic Kuramoto-Sivashinsky
equation and stochastically-forced beta-plane turbulence, showcasing its
ability to capture phenomena at interpolated parameter values. The emulator
provides significant computational speed-ups over conventional numerical
integration, facilitating efficient exploration of parameter space, while a
probabilistic variant of the emulator provides uncertainty quantification,
allowing for the statistical study of rare events.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph Alignment via Dual-Pass Spectral Encoding and Latent Space
  Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maysam Behmanesh, Erkan Turan, Maks Ovsjanikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph alignment-the problem of identifying corresponding nodes across
multiple graphs-is fundamental to numerous applications. Most existing
unsupervised methods embed node features into latent representations to enable
cross-graph comparison without ground-truth correspondences. However, these
methods suffer from two critical limitations: the degradation of node
distinctiveness due to oversmoothing in GNN-based embeddings, and the
misalignment of latent spaces across graphs caused by structural noise, feature
heterogeneity, and training instability, ultimately leading to unreliable node
correspondences. We propose a novel graph alignment framework that
simultaneously enhances node distinctiveness and enforces geometric consistency
across latent spaces. Our approach introduces a dual-pass encoder that combines
low-pass and high-pass spectral filters to generate embeddings that are both
structure-aware and highly discriminative. To address latent space
misalignment, we incorporate a geometry-aware functional map module that learns
bijective and isometric transformations between graph embeddings, ensuring
consistent geometric relationships across different representations. Extensive
experiments on graph benchmarks demonstrate that our method consistently
outperforms existing unsupervised alignment baselines, exhibiting superior
robustness to structural inconsistencies and challenging alignment scenarios.
Additionally, comprehensive evaluation on vision-language benchmarks using
diverse pretrained models shows that our framework effectively generalizes
beyond graph domains, enabling unsupervised alignment of vision and language
representations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ObjectReact: Learning Object-Relative Control for Visual Navigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sourav Garg, Dustin Craggs, Vineeth Bhat, Lachlan Mares, Stefan Podgorski, Madhava Krishna, Feras Dayoub, Ian Reid
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual navigation using only a single camera and a topological map has
recently become an appealing alternative to methods that require additional
sensors and 3D maps. This is typically achieved through an "image-relative"
approach to estimating control from a given pair of current observation and
subgoal image. However, image-level representations of the world have
limitations because images are strictly tied to the agent's pose and
embodiment. In contrast, objects, being a property of the map, offer an
embodiment- and trajectory-invariant world representation. In this work, we
present a new paradigm of learning "object-relative" control that exhibits
several desirable characteristics: a) new routes can be traversed without
strictly requiring to imitate prior experience, b) the control prediction
problem can be decoupled from solving the image matching problem, and c) high
invariance can be achieved in cross-embodiment deployment for variations across
both training-testing and mapping-execution settings. We propose a topometric
map representation in the form of a "relative" 3D scene graph, which is used to
obtain more informative object-level global path planning costs. We train a
local controller, dubbed "ObjectReact", conditioned directly on a high-level
"WayObject Costmap" representation that eliminates the need for an explicit RGB
input. We demonstrate the advantages of learning object-relative control over
its image-relative counterpart across sensor height variations and multiple
navigation tasks that challenge the underlying spatial understanding
capability, e.g., navigating a map trajectory in the reverse direction. We
further show that our sim-only policy is able to generalize well to real-world
indoor environments. Code and supplementary material are accessible via project
page: https://object-react.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CoRL 2025; 23 pages including appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Demo: Healthcare Agent Orchestrator (HAO) for Patient Summarization in
  Molecular Tumor Boards 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06602v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06602v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthias Blondeel, Noel Codella, Sam Preston, Hao Qiu, Leonardo Schettini, Frank Tuan, Wen-wai Yim, Smitha Saligrama, Mert Öz, Shrey Jain, Matthew P. Lungren, Thomas Osborne
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Molecular Tumor Boards (MTBs) are multidisciplinary forums where oncology
specialists collaboratively assess complex patient cases to determine optimal
treatment strategies. A central element of this process is the patient summary,
typically compiled by a medical oncologist, radiation oncologist, or surgeon,
or their trained medical assistant, who distills heterogeneous medical records
into a concise narrative to facilitate discussion. This manual approach is
often labor-intensive, subjective, and prone to omissions of critical
information. To address these limitations, we introduce the Healthcare Agent
Orchestrator (HAO), a Large Language Model (LLM)-driven AI agent that
coordinates a multi-agent clinical workflow to generate accurate and
comprehensive patient summaries for MTBs. Evaluating predicted patient
summaries against ground truth presents additional challenges due to stylistic
variation, ordering, synonym usage, and phrasing differences, which complicate
the measurement of both succinctness and completeness. To overcome these
evaluation hurdles, we propose TBFact, a ``model-as-a-judge'' framework
designed to assess the comprehensiveness and succinctness of generated
summaries. Using a benchmark dataset derived from de-identified tumor board
discussions, we applied TBFact to evaluate our Patient History agent. Results
show that the agent captured 94% of high-importance information (including
partial entailments) and achieved a TBFact recall of 0.84 under strict
entailment criteria. We further demonstrate that TBFact enables a data-free
evaluation framework that institutions can deploy locally without sharing
sensitive clinical data. Together, HAO and TBFact establish a robust foundation
for delivering reliable and scalable support to MTBs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 1 figure; Added missing co-authors and contributors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Investigating Energy Efficiency and Performance Trade-offs in <span class="highlight-title">LLM</span>
  <span class="highlight-title">Inference</span> Across Tasks and DVFS Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.08219v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.08219v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Joe Maliakel, Shashikant Ilager, Ivona Brandic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing (NLP) tasks, leading to widespread
adoption in both research and industry. However, their inference workloads are
computationally and energy intensive, raising concerns about sustainability and
environmental impact. As LLMs continue to scale, it becomes essential to
identify and optimize the factors that influence their runtime efficiency
without compromising performance. In this work, we systematically investigate
the energy-performance trade-offs of LLMs during inference. We benchmark models
of varying sizes and architectures, including Falcon-7B, Mistral-7B-v0.1,
LLaMA-3.2-1B, LLaMA-3.2-3B, and GPT-Neo-2.7B, across tasks such as question
answering, commonsense reasoning, and factual generation. We analyze the effect
of input characteristics, such as sequence length, entropy, named entity
density and so on. Furthermore, we examine the impact of hardware-level
optimizations through Dynamic Voltage and Frequency Scaling (DVFS), measuring
how different GPU clock settings affect latency and power consumption. Our
empirical findings show that model architecture, input complexity, and clock
configuration significantly influence inference efficiency. By correlating
input features with energy metrics and evaluating DVFS behavior, we identify
practical strategies that reduce energy consumption by up to 30% while
preserving model quality. This study provides actionable insights for designing
energy-efficient and sustainable LLM inference systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MM-Prompt: Cross-Modal Prompt Tuning for Continual Visual Question
  Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.19455v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.19455v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xu Li, Fan Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Continual Visual Question Answering (CVQA) based on pre-trained models(PTMs)
has achieved promising progress by leveraging prompt tuning to enable continual
multi-modal learning. However, most existing methods adopt cross-modal prompt
isolation, constructing visual and textual prompts separately, which
exacerbates modality imbalance and leads to degraded performance over time. To
tackle this issue, we propose MM-Prompt, a novel framework incorporating
cross-modal prompt query and cross-modal prompt recovery. The former enables
balanced prompt selection by incorporating cross-modal signals during query
formation, while the latter promotes joint prompt reconstruction through
iterative cross-modal interactions, guided by an alignment loss to prevent
representational drift. Extensive experiments show that MM-Prompt surpasses
prior approaches in accuracy and knowledge retention, while maintaining
balanced modality engagement throughout continual learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Modular Jump Gaussian Processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2505.15557v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2505.15557v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna R. Flowers, Christopher T. Franck, Mickaël Binois, Chiwoo Park, Robert B. Gramacy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gaussian processes (GPs) furnish accurate nonlinear predictions with
well-calibrated uncertainty. However, the typical GP setup has a built-in
stationarity assumption, making it ill-suited for modeling data from processes
with sudden changes, or "jumps" in the output variable. The "jump GP" (JGP) was
developed for modeling data from such processes, combining local GPs and latent
"level" variables under a joint inferential framework. But joint modeling can
be fraught with difficulty. We aim to simplify by suggesting a more modular
setup, eschewing joint inference but retaining the main JGP themes: (a)
learning optimal neighborhood sizes that locally respect manifolds of
discontinuity; and (b) a new cluster-based (latent) feature to capture regions
of distinct output levels on both sides of the manifold. We show that each of
(a) and (b) separately leads to dramatic improvements when modeling processes
with jumps. In tandem (but without requiring joint inference) that benefit is
compounded, as illustrated on real and synthetic benchmark examples from the
recent literature.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human
  Preference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06942v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06942v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangwei Shen, Zhimin Li, Zhantao Yang, Shiyi Zhang, Yingfang Zhang, Donghao Li, Chunyu Wang, Qinglin Lu, Yansong Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have demonstrated the effectiveness of directly aligning
diffusion models with human preferences using differentiable reward. However,
they exhibit two primary challenges: (1) they rely on multistep denoising with
gradient computation for reward scoring, which is computationally expensive,
thus restricting optimization to only a few diffusion steps; (2) they often
need continuous offline adaptation of reward models in order to achieve desired
aesthetic quality, such as photorealism or precise lighting effects. To address
the limitation of multistep denoising, we propose Direct-Align, a method that
predefines a noise prior to effectively recover original images from any time
steps via interpolation, leveraging the equation that diffusion states are
interpolations between noise and target images, which effectively avoids
over-optimization in late timesteps. Furthermore, we introduce Semantic
Relative Preference Optimization (SRPO), in which rewards are formulated as
text-conditioned signals. This approach enables online adjustment of rewards in
response to positive and negative prompt augmentation, thereby reducing the
reliance on offline reward fine-tuning. By fine-tuning the FLUX model with
optimized denoising and online reward adjustment, we improve its
human-evaluated realism and aesthetic quality by over 3x.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07715v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07715v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aya Kayal, Sattar Vakili, Laura Toni, Alberto Bernacchia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning (RL) problems are being considered under increasingly
more complex structures. While tabular and linear models have been thoroughly
explored, the analytical study of RL under nonlinear function approximation,
especially kernel-based models, has recently gained traction for their strong
representational capacity and theoretical tractability. In this context, we
examine the question of statistical efficiency in kernel-based RL within the
reward-free RL framework, specifically asking: how many samples are required to
design a near-optimal policy? Existing work addresses this question under
restrictive assumptions about the class of kernel functions. We first explore
this question by assuming a generative model, then relax this assumption at the
cost of increasing the sample complexity by a factor of H, the length of the
episode. We tackle this fundamental problem using a broad class of kernels and
a simpler algorithm compared to prior work. Our approach derives new confidence
intervals for kernel ridge regression, specific to our RL setting, which may be
of broader applicability. We further validate our theoretical findings through
simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at AISTATS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AU-Harness: An Open-Source Toolkit for Holistic Evaluation of Audio <span class="highlight-title">LLM</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sidharth Surapaneni, Hoang Nguyen, Jash Mehta, Aman Tiwari, Oluwanifemi Bamgbose, Akshay Kalkunte, Sai Rajeswar, Sathwik Tejaswi Madhusudhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Audio Language Models (LALMs) are rapidly advancing, but evaluating
them remains challenging due to inefficient toolkits that limit fair comparison
and systematic assessment. Current frameworks suffer from three critical
issues: slow processing that bottlenecks large-scale studies, inconsistent
prompting that hurts reproducibility, and narrow task coverage that misses
important audio reasoning capabilities. We introduce AU-Harness, an efficient
and comprehensive evaluation framework for LALMs. Our system achieves a speedup
of up to 127% over existing toolkits through optimized batch processing and
parallel execution, enabling large-scale evaluations previously impractical. We
provide standardized prompting protocols and flexible configurations for fair
model comparison across diverse scenarios. Additionally, we introduce two new
evaluation categories: LLM-Adaptive Diarization for temporal audio
understanding and Spoken Language Reasoning for complex audio-based cognitive
tasks. Through evaluation across 380+ tasks, we reveal significant gaps in
current LALMs, particularly in temporal understanding and complex spoken
language reasoning tasks. Our findings also highlight a lack of standardization
in instruction modality existent across audio benchmarks, which can lead up
performance differences up to 9.5 absolute points on the challenging complex
instruction following downstream tasks. AU-Harness provides both practical
evaluation tools and insights into model limitations, advancing systematic LALM
development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Critical Challenges and Guidelines in Evaluating Synthetic Tabular Data:
  A Systematic Review 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2504.18544v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2504.18544v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazia Nafis, Inaki Esnaola, Alvaro Martinez-Perez, Maria-Cruz Villa-Uriol, Venet Osmani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating synthetic tabular data can be challenging, however evaluation of
their quality is just as challenging, if not more. This systematic review sheds
light on the critical importance of rigorous evaluation of synthetic health
data to ensure reliability, relevance, and their appropriate use. Based on
screening of 1766 papers and a detailed review of 101 papers we identified key
challenges, including lack of consensus on evaluation methods, improper use of
evaluation metrics, limited input from domain experts, inadequate reporting of
dataset characteristics, and limited reproducibility of results. In response,
we provide several guidelines on the generation and evaluation of synthetic
data, to allow the community to unlock and fully harness the transformative
potential of synthetic data and accelerate innovation.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Programming Languages
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring the Theory and Practice of Concurrency in the
  Entity-Component-System Pattern 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.15264v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.15264v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Redmond, Jonathan Castello, José Manuel Calderón Trilla, Lindsey Kuper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Entity-Component-System (ECS) software design pattern, long used in game
development, encourages a clean separation of identity (entities), data
properties (components), and computational behaviors (systems). Programs
written using the ECS pattern are naturally concurrent, and the pattern offers
modularity, flexibility, and performance benefits that have led to a
proliferation of ECS frameworks. Nevertheless, the ECS pattern is little-known
and not well understood outside of a few domains. Existing explanations of the
ECS pattern tend to be mired in the concrete details of particular ECS
frameworks, or they explain the pattern in terms of imperfect metaphors or in
terms of what it is not. We seek a rigorous understanding of the ECS pattern
via the design of a formal model, Core ECS, that abstracts away the details of
specific implementations to reveal the essence of software using the ECS
pattern. We identify a class of Core ECS programs that behave deterministically
regardless of scheduling, enabling use of the ECS pattern as a
deterministic-by-construction concurrent programming model. With Core ECS as a
point of comparison, we then survey several real-world ECS frameworks and find
that they all leave opportunities for deterministic concurrency unexploited.
Our findings point out a space for new ECS implementation techniques that
better leverage such opportunities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is an extended version (with appendices) of the OOPSLA 2025
  paper</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-09-10T00:00:00Z">2025-09-10</time>
        </div>
            <article>
                <details>
                    <Summary>
                        High Energy Physics - Experimental
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fabrication of thin planar radiopure foils with 82Se for the SuperNEMO
  Demonstrator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08931v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08931v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        X. Aguerre, A. Barabash, A. Basharina-Freshville, M. Bongrand, Ch. Bourgeois, D. Breton, R. Breier, J. Busto, C. Cerna, J. Cesar, M. Ceschia, E. Chauveau, S. De Capua, D. Duchesneau, J. J. Evans, D. V. Filosofov, M. Granjon, M. Hoballah, R. Hodák, J. Horkley, A. Jeremie, S. Jullian, J. Kaizer, A. A. Klimenko, O. Kochetov, F. Koňařík, S. Konovalov, T. Křižák, A. Lahaie, K. Lang, Y. Lemière, T. Le Noblet, P. Li, P. Loaiza, J. Maalmi, M. Macko, F. Mamedov, C. Marquet, F. Mauger, A. Mendl, B. Morgan, I. Nemchenok, V. Palušová, C. Patrick, F. Perrot, M. Petro, F. Piquemal, P. Povinec, S. Pratt, M. Proga, W. S. Quinn, A. V. Rakhimov, Y. R amachers, A. Remoto, N. I. Rukhadze, R. Saakyan, R. Salazar, J. Sedgbeer, Y. Shitov, L. Simard, F. Šimkovic, A. A. Smolnikov, S. Söldner-Rembold, I. Štekl, J. Suhonen, H. Tedjditi, J. Thomas, V. Timkin, V. Tretyak, V. I. Tretyak, G. Turnbull, Y. Vereshchaka, G. Warot, D. Waters, V. Yumatov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The SuperNEMO Demonstrator, designed to search for double beta decay using
enriched 82Se, has been assembled in the Modane Underground Laboratory under
the French Alps. Thin foils with radio - purified and enriched 82Se are
installed centrally in the detector. A novel foil fabrication method has been
developed, improving the radiopurity achieved in the previous generation
experiment. It consists of wrapping standalone selenium pads in raw Mylar,
combined with selenium purified by a new reverse-chromatography method. This
paper describes the features of these foils, their fabrication process, the
characterization results, and the integration of the foils into the SuperNEMO
Demonstrator.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 11 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ORLCA: A concept for an open-source Life Cycle Assessment repository
  built for research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08901v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08901v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hannah Wakeling, Kristin Lohwasser, Peter Millington
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Comprehensive Life Cycle Assessment (LCA) as a tool to account for the full
range of environmental impacts of resource use in commodities or services is a
first step in reducing these impacts. There is an increasing necessity to
account for these aspects in the planning, running and end-of-life of
scientific experiments and research infrastructure. In the following, the
concept for an Open Research Life Cycle Assessment (ORLCA) repository is
presented to support this endeavour. It is designed to comply fully with the
principles of findability, accessibility, interoperability, and reusability
(FAIR).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finding Unexpected Non-Helical Tracks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08878v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08878v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Levi Condren, Daniel Whiteson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many theories of physics beyond the Standard Model predict particles with
non-helical trajectories in a uniform magnetic field, but standard tracking
algorithms assume helical paths and so are incapable of discovering non-helical
tracks. While alternative algorithms have been developed for specific
trajectories, unforeseen physics could lead to unanticipated behavior, and such
unexpected tracks are largely invisible to current algorithms, despite being
potentially striking to the naked eye. A model-agnostic tracking algorithm is
presented, capable of reconstructing a broad class of smooth non-helical tracks
without requiring explicit specification of particle trajectories, instead
defining the target trajectories implicitly in the training sample. The network
exhibits strong performance, even outside of the trajectories defined by the
training sample. This proof-of-principle study takes the first step towards
searches for unexpected tracks which may await discovery in current data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measurement of the space-like $π^0$ transition form factor 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.07685v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.07685v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Based on $2.93\,\text{fb}^{-1}$ of $e^+e^-$ collision data taken with the
BESIII detector at a center-of-mass energy of $3.773\,\text{GeV}$, the
two-photon fusion process $e^+e^-\to e^+e^-\pi^0$ is investigated using a
single-tag approach. The differential Born cross section
$\text{d}\sigma/\text{d}Q^2$ and the space-like transition form factor
$|F(Q^2)|$ of the $\pi^0$ are measured as functions of the squared momentum
transfer $Q^2$ of the tagged, scattered lepton. The measurement covers the
range $0.2 < Q^2 < 3.5\,\text{GeV}^2$. The results are consistent with previous
measurements, and provide a significant improvement for $Q^2<2\,\text{GeV}^2$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 3 figures, submitted to Phys.Lett.B</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Phase space compression of a positive muon beam in two spatial
  dimensions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21162v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21162v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        A. Antognini, N. J. Ayres, I. Belosevic, V. Bondar, A. Eggenberger, M. Hildebrandt, R. Iwai, K. Kirch, A. Knecht, G. Lospalluto, J. Nuber, A. Papa, M. Sakurai, I. Solovyev, D. Taqqu, T. Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the first demonstration of simultaneous phase space compression in
two spatial dimensions of a positive muon beam, the first stage of the novel
high-brightness muon beam under development by the muCool collaboration at the
Paul Scherrer Institute. The keV-energy, sub-mm size beam would enable a factor
10$^5$ improvement in brightness for precision muSR, and atomic and particle
physics measurements with positive muons. This compression is achieved within a
cryogenic helium gas target with a strong density gradient, placed in a
homogeneous magnetic field, under the influence of a complex electric field. In
the next phase, the muon beam will be extracted into vacuum.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submission to SciPost</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gain characterization of LGAD sensors with beta particles and 28-MeV
  protons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2503.07941v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2503.07941v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Hijas Mohamed Farook, Gabriele Giacomini, Gabriele DAmen, Giovanni Pinaroli, Enrico Rossi, Sally Seidel, Alessandro Tricoli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low Gain Avalanche Diodes, also known as LGADs, are widely considered for
fast-timing applications in high energy physics, nuclear physics, space
science, medical imaging, and precision measurements of rare processes. Such
devices are silicon-based and feature an intrinsic gain due to a $p{^+}$-doped
layer that allows the production of a controlled avalanche of carriers, with
multiplication on the order of 10-100. This technology can provide time
resolution on the order of 20-30 ps, and variants of this technology can
provide precision tracking too. The characterization of LGAD performance has so
far primarily been focused on the interaction of minimum ionizing particles for
high energy and nuclear physics applications. This article expands the study of
LGAD performance to highly-ionizing particles, such as 28-MeV protons, which
are relevant for several future scientific applications, e.g. in biology and
medical physics, among others. These studies were performed with a beam of
28-MeV protons from a tandem Van de Graaff accelerator at Brookhaven National
Laboratory and beta particles from a $^{90}{\rm Sr}$ source; these were used to
characterize the response and the gain of an LGAD as a function of bias voltage
and collected charge. The experimental results are also compared to TCAD
simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to JINST</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning - Statistics
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Similarity-based Outlier Detection for Noisy Object Re-Identification
  Using Beta Mixtures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08926v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08926v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Waqar Ahmad, Evan Murphy, Vladimir A. Krylov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object re-identification (Re-ID) methods are highly sensitive to label noise,
which typically leads to significant performance degradation. We address this
challenge by reframing Re-ID as a supervised image similarity task and adopting
a Siamese network architecture trained to capture discriminative pairwise
relationships. Central to our approach is a novel statistical outlier detection
(OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier
Detection), which models the distribution of cosine similarities between
embedding pairs using a two-component Beta distribution mixture model. We
establish a novel identifiability result for mixtures of two Beta
distributions, ensuring that our learning task is well-posed.The proposed OD
step complements the Re-ID architecture combining binary cross-entropy,
contrastive, and cosine embedding losses that jointly optimize feature-level
similarity learning.We demonstrate the effectiveness of Beta-SOD in de-noising
and Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and
vehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance
compared to the state-of-the-art methods across various noise levels (10-30\%),
demonstrating both robustness and broad applicability in noisy Re-ID scenarios.
The implementation of Beta-SOD is available at:
https://github.com/waqar3411/Beta-SOD
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum
  Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08911v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08911v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weiyuan Gong, Tongyang Li, Xinzhao Wang, Zhiyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning
algorithm with numerous applications. Applied to the matrix version of the
Learning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex,
it is well known that MMWU achieves the minimax-optimal regret bound of
$O(\sqrt{T\log d})$, where $T$ is the time horizon. In this paper, we present
an improved algorithm achieving the instance-optimal regret bound of
$O(\sqrt{T\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret,
$I_d$ is the identity matrix, and $S(\cdot||\cdot)$ denotes the quantum
relative entropy. Furthermore, our algorithm has the same computational
complexity as MMWU, indicating that the improvement in the regret bound is
``free''.
  Technically, we first develop a general potential-based framework for matrix
LEA, with MMWU being its special case induced by the standard exponential
potential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace
inequality built on a Laplace transform technique, which allows the application
of general potential functions beyond exponential to matrix LEA. Our algorithm
is finally induced by an optimal potential function from the vector LEA
problem, based on the imaginary error function.
  Complementing the above, we provide a memory lower bound for matrix LEA, and
explore the applications of our algorithm in quantum learning theory. We show
that it outperforms the state of the art for learning quantum states corrupted
by depolarization noise, random quantum states, and Gibbs states. In addition,
applying our algorithm to linearized convex losses enables predicting nonlinear
quantum properties, such as purity, quantum virtual cooling, and R\'{e}nyi-$2$
correlation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>47 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Narrative-Guided Reinforcement Learning: A Platform for Studying
  Language Model Influence on Decision Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08785v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08785v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anup Tuladhar, Araz Minhas, Adam Kirton, Eli Kinney-Lang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended Abstract for RLDM 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data-Augmented <span class="highlight-title">Few-Shot</span> <span class="highlight-title">Neural</span> Stencil Emulation for System
  Identification of Computer Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.19441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.19441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sanket Jantre, Deepak Akhare, Xiaoning Qian, Nathan M. Urban
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptive kernel predictors from feature-learning infinite limits of
  <span class="highlight-title">neural</span> networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07998v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07998v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Clarissa Lauditi, Blake Bordelon, Cengiz Pehlevan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous influential work showed that infinite width limits of neural
networks in the lazy training regime are described by kernel machines. Here, we
show that neural networks trained in the rich, feature learning infinite-width
regime in two different settings are also described by kernel machines, but
with data-dependent kernels. For both cases, we provide explicit expressions
for the kernel predictors and prescriptions to numerically calculate them. To
derive the first predictor, we study the large-width limit of feature-learning
Bayesian networks, showing how feature learning leads to task-relevant
adaptation of layer kernels and preactivation densities. The saddle point
equations governing this limit result in a min-max optimization problem that
defines the kernel predictor. To derive the second predictor, we study gradient
flow training of randomly initialized networks trained with weight decay in the
infinite-width limit using dynamical mean field theory (DMFT). The fixed point
equations of the arising DMFT defines the task-adapted internal representations
and the kernel predictor. We compare our kernel predictors to kernels derived
from lazy regime and demonstrate that our adaptive kernels achieve lower test
loss on benchmark datasets.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Programming Languages
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dependent-Type-Preserving Memory Allocation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09059v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09059v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paulette Koronkevich, William J. Bowman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dependently typed programming languages such as Coq, Agda, Idris, and F*,
allow programmers to write detailed specifications of their programs and prove
their programs meet these specifications. However, these specifications can be
violated during compilation since they are erased after type checking. External
programs linked with the compiled program can violate the specifications of the
original program and change the behavior of the compiled program -- even when
compiled with a verified compiler. For example, since Coq does not allow
explicitly allocating memory, a programmer might link their Coq program with a
C program that can allocate memory. Even if the Coq program is compiled with a
verified compiler, the external C program can still violate the memory-safe
specification of the Coq program by providing an uninitialized pointer to
memory. This error could be ruled out by type checking in a language expressive
enough to indicate whether memory is initialized versus uninitialized. Linking
with a program with an uninitialized pointer could be considered ill-typed, and
our linking process could prevent linking with ill-typed programs. To
facilitate type checking during linking, we can use type-preserving
compilation, which preserves the types through the compilation process. In this
ongoing work, we develop a typed intermediate language that supports dependent
memory allocation, as well as a dependent-type-preserving compiler pass for
memory allocation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted and received second place at the Student Research
  Competition at Principles of Programming Languages 2022</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Verified Compilation of Floating-point Optimization in
  Scientific Computing Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.09019v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.09019v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohit Tekriwal, John Sarracino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific computing programs often undergo aggressive compiler optimization
to achieve high performance and efficient resource utilization. While
performance is critical, we also need to ensure that these optimizations are
correct. In this paper, we focus on a specific class of optimizations,
floating-point optimizations, notably due to fast math, at the LLVM IR level.
We present a preliminary work, which leverages the Verified LLVM framework in
the Rocq theorem prover, to prove the correctness of Fused-Multiply-Add (FMA)
optimization for a basic block implementing the arithmetic expression $a * b +
c$ . We then propose ways to extend this preliminary results by adding more
program features and fast math floating-point optimizations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Approximate Algorithms for Verifying Differential Privacy with Gaussian
  Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08804v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08804v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bishnu Bhusal, Rohit Chadha, A. Prasad Sistla, Mahesh Viswanathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The verification of differential privacy algorithms that employ Gaussian
distributions is little understood. This paper tackles the challenge of
verifying such programs by introducing a novel approach to approximating
probability distributions of loop-free programs that sample from both discrete
and continuous distributions with computable probability density functions,
including Gaussian and Laplace. We establish that verifying
$(\epsilon,\delta)$-differential privacy for these programs is \emph{almost
decidable}, meaning the problem is decidable for all values of $\delta$ except
those in a finite set. Our verification algorithm is based on computing
probabilities to any desired precision by combining integral approximations,
and tail probability bounds. The proposed methods are implemented in the tool,
DipApprox, using the FLINT library for high-precision integral computations,
and incorporate optimizations to enhance scalability. We validate {\ourtool} on
fundamental privacy-preserving algorithms, such as Gaussian variants of the
Sparse Vector Technique and Noisy Max, demonstrating its effectiveness in both
confirming privacy guarantees and detecting violations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>An extended abstract appears in CCS 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Securing Cryptographic Software via Typed Assembly Language (Extended
  Version) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shixin Song, Tingzhen Dong, Kosi Nwabueze, Julian Zanders, Andres Erbsen, Adam Chlipala, Mengjia Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Authors of cryptographic software are well aware that their code should not
leak secrets through its timing behavior, and, until 2018, they believed that
following industry-standard constant-time coding guidelines was sufficient.
However, the revelation of the Spectre family of speculative execution attacks
injected new complexities.
  To block speculative attacks, prior work has proposed annotating the
program's source code to mark secret data, with hardware using this information
to decide when to speculate (i.e., when only public values are involved) or not
(when secrets are in play). While these solutions are able to track secret
information stored on the heap, they suffer from limitations that prevent them
from correctly tracking secrets on the stack, at a cost in performance.
  This paper introduces SecSep, a transformation framework that rewrites
assembly programs so that they partition secret and public data on the stack.
By moving from the source-code level to assembly rewriting, SecSep is able to
address limitations of prior work. The key challenge in performing this
assembly rewriting stems from the loss of semantic information through the
lengthy compilation process. The key innovation of our methodology is a new
variant of typed assembly language (TAL), Octal, which allows us to address
this challenge. Assembly rewriting is driven by compile-time inference within
Octal. We apply our technique to cryptographic programs and demonstrate that it
enables secure speculation efficiently, incurring a low average overhead of
$1.2\%$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hiord#: An Approach to the Specification and Verification of
  Higher-Order (C)LP Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2507.17233v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2507.17233v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marco Ciccalè, Daniel Jurjo-Rivas, Jose F. Morales, Pedro López-García, Manuel V. Hermenegildo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Higher-order constructs enable more expressive and concise code by allowing
procedures to be parameterized by other procedures. Assertions allow expressing
partial program specifications, which can be verified either at compile time
(statically) or run time (dynamically). In higher-order programs, assertions
can also describe higher-order arguments. While in the context of (constraint)
logic programming ((C)LP), run-time verification of higher-order assertions has
received some attention, compile-time verification remains relatively
unexplored. We propose a novel approach for statically verifying higher-order
(C)LP programs with higher-order assertions. Although we use the Ciao assertion
language for illustration, our approach is quite general and we believe is
applicable to similar contexts. Higher-order arguments are described using
predicate properties -- a special kind of property which exploits the (Ciao)
assertion language. We refine the syntax and semantics of these properties and
introduce an abstract criterion to determine conformance to a predicate
property at compile time, based on a semantic order relation comparing the
predicate property with the predicate assertions. We then show how to handle
these properties using an abstract interpretation-based static analyzer for
programs with first-order assertions by reducing predicate properties to
first-order properties. Finally, we report on a prototype implementation and
evaluate it through various examples within the Ciao system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication in Theory and Practice of Logic Programming
  (TPLP)</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-09-09T00:00:00Z">2025-09-09</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Programming Languages
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics,
  Convergence Guarantees, and Human-AI Protocols 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.08182v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.08182v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faruk Alpay, Taylan Alpay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Structured prompting with XML tags has emerged as an effective way to steer
large language models (LLMs) toward parseable, schema-adherent outputs in
real-world systems. We develop a logic-first treatment of XML prompting that
unifies (i) grammar-constrained decoding, (ii) fixed-point semantics over
lattices of hierarchical prompts, and (iii) convergent human-AI interaction
loops. We formalize a complete lattice of XML trees under a refinement order
and prove that monotone prompt-to-prompt operators admit least fixed points
(Knaster-Tarski) that characterize steady-state protocols; under a task-aware
contraction metric on trees, we further prove Banach-style convergence of
iterative guidance. We instantiate these results with context-free grammars
(CFGs) for XML schemas and show how constrained decoding guarantees
well-formedness while preserving task performance. A set of multi-layer
human-AI interaction recipes demonstrates practical deployment patterns,
including multi-pass "plan $\to$ verify $\to$ revise" routines and agentic tool
use. We provide mathematically complete proofs and tie our framework to recent
advances in grammar-aligned decoding, chain-of-verification, and programmatic
prompting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, multiple XML prompts</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Were You Thinking? An <span class="highlight-title">LLM</span>-Driven Large-Scale Study of Refactoring
  Motivations in Open-Source Projects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.07763v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.07763v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikel Robredo, Matteo Esposito, Fabio Palomba, Rafael Peñaloza, Valentina Lenarduzzi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Context. Code refactoring improves software quality without changing external
behavior. Despite its advantages, its benefits are hindered by the considerable
cost of time, resources, and continuous effort it demands. Aim. Understanding
why developers refactor, and which metrics capture these motivations, may
support wider and more effective use of refactoring in practice. Method. We
performed a large-scale empirical study to analyze developers refactoring
activity, leveraging Large Language Models (LLMs) to identify underlying
motivations from version control data, comparing our findings with previous
motivations reported in the literature. Results. LLMs matched human judgment in
80% of cases, but aligned with literature-based motivations in only 47%. They
enriched 22% of motivations with more detailed rationale, often highlighting
readability, clarity, and structural improvements. Most motivations were
pragmatic, focused on simplification and maintainability. While metrics related
to developer experience and code readability ranked highest, their correlation
with motivation categories was weak. Conclusions. We conclude that LLMs
effectively capture surface-level motivations but struggle with architectural
reasoning. Their value lies in providing localized explanations, which, when
combined with software metrics, can form hybrid approaches. Such integration
offers a promising path toward prioritizing refactoring more systematically and
balancing short-term improvements with long-term architectural goals.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What's in the Box: Ergonomic and Expressive Capture <span class="highlight-title">Tracking</span> over
  Generic Data Structures (Extended Version) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.07609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.07609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichen Xu, Oliver Bračevac, Cao Nguyen Pham, Martin Odersky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Capturing types in Scala unify static effect and resource tracking with
object capabilities, enabling lightweight effect polymorphism with minimal
notational overhead. However, their expressiveness has been insufficient for
tracking capabilities embedded in generic data structures, preventing them from
scaling to the standard collections library -- an essential prerequisite for
broader adoption. This limitation stems from the inability to name capabilities
within the system's notion of box types.
  This paper develops System Capless, a new foundation for capturing types that
provides the theoretical basis for reach capabilities (rcaps), a novel
mechanism for naming "what's in the box." The calculus refines the universal
capability notion into a new scheme with existential and universal capture set
quantification. Intuitively, rcaps witness existentially quantified capture
sets inside the boxes of generic types in a way that does not require exposing
existential capture types in the surface language. We have fully mechanized the
formal metatheory of System Capless in Lean, including proofs of type soundness
and scope safety. System Capless supports the same lightweight notation of
capturing types plus rcaps, as certified by a type-preserving translation, and
also enables fully optional explicit capture-set quantification to increase
expressiveness.
  Finally, we present a full reimplementation of capture checking in Scala 3
based on System Capless and migrate the entire Scala collections library and an
asynchronous programming library to evaluate its practicality and ergonomics.
Our results demonstrate that reach capabilities enable the adoption of capture
checking in production code with minimal changes and minimal-to-zero notational
overhead in a vast majority of cases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast and Extensible Hybrid <span class="highlight-title">Embedding</span>s with Micros 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.07551v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.07551v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sean Bocirnea, William J. Bowman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Macro embedding is a popular approach to defining extensible shallow
embeddings of object languages in Scheme like host languages. While macro
embedding has even been shown to enable implementing extensible typed languages
in systems like Racket, it comes at a cost: compile-time performance. In this
paper, we revisit micros - syntax to intermediate representation (IR)
transformers, rather than source syntax to source syntax transformers (macros).
Micro embedding enables stopping at an IR, producing a deep embedding and
enabling high performance compile-time functions over an efficient IR, before
shallowly embedding the IR back into source syntax. Combining micros with
several design patterns to enable the IR and functions over it to be
extensible, we achieve extensible hybrid embedding of statically typed
languages with significantly improved compile-time compared to macro-embedding
approaches. We describe our design patterns and propose new abstractions
packaging these patterns.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-09-08T00:00:00Z">2025-09-08</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Programming Languages
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mechanized Metatheory of Forward Reasoning for End-to-End
  Linearizability Proofs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06872v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06872v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zachary Kent, Ugur Y. Yavuz, Siddhartha Jayanti, Stephanie Balzer, Guy Blelloch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the past decade, many techniques have been developed to prove
linearizability, the gold standard of correctness for concurrent data
structures. Intuitively, linearizability requires that every operation on a
concurrent data structure appears to take place instantaneously, even when
interleaved with other operations. Most recently, Jayanti et al. presented the
first sound and complete "forward reasoning" technique for proving
linearizability that relates the behavior of a concurrent data structure to a
reference atomic data structure as time moves forward. This technique can be
used to produce machine-checked proofs of linearizability in TLA+. However,
while Jayanti et al.'s approach is shown to be sound and complete, a
mechanization of this important metatheoretic result is still outstanding. As a
result, it is not possible to produce verified end-to-end proofs of
linearizability. To reduce the size of this trusted computing base, we
formalize this forward reasoning technique and mechanize proofs of its
soundness and completeness in Rocq. As a case study, we use the approach to
produce a verified end-to-end proof of linearizability for a simple concurrent
register.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIO: Multiverse Debugging in the Face of Input/Output -- Extended
  Version with Additional Appendices 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06845v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06845v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tom Lauwaerts, Maarten Steevens, Christophe Scholliers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Debugging non-deterministic programs on microcontrollers is notoriously
challenging, especially when bugs manifest in unpredictable, input-dependent
execution paths. A recent approach, called multiverse debugging, makes it
easier to debug non-deterministic programs by allowing programmers to explore
all potential execution paths. Current multiverse debuggers enable both forward
and backward traversal of program paths, and some facilitate jumping to any
previously visited states, potentially branching into alternative execution
paths within the state space.
  Unfortunately, debugging programs that involve input/output operations using
existing multiverse debuggers can reveal inaccessible program states, i.e.
states which are not encountered during regular execution. This can
significantly hinder the debugging process, as the programmer may spend
substantial time exploring and examining inaccessible program states, or worse,
may mistakenly assume a bug is present in the code, when in fact, the issue is
caused by the debugger.
  This paper presents a novel approach to multiverse debugging, which can
accommodate a broad spectrum of input/output operations. We provide the
semantics of our approach and prove the correctness of our debugger, ensuring
that despite having support for a wide range of input/output operations the
debugger will only explore those program states which can be reached during
regular execution.
  We have developed a prototype, called MIO, leveraging the WARDuino
WebAssembly virtual machine to demonstrate the feasibility and efficiency of
our techniques. As a demonstration of the approach we highlight a color dial
built with a Lego Mindstorms motor, and color sensor, providing a tangible
example of how our approach enables multiverse debugging for programs running
on an STM32 microcontroller.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This extended version provides auxiliary material to the article of
  the same title that will appear in the ACM Digital Library as part of the
  PACMPL issue for OOPSLA 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dato: A Task-Based Programming Model for Dataflow Accelerators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06794v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06794v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shihan Fang, Hongzheng Chen, Niansong Zhang, Jiajie Li, Han Meng, Adrian Liu, Zhiru Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent deep learning workloads increasingly push computational demand beyond
what current memory systems can sustain, with many kernels stalling on data
movement rather than computation. While modern dataflow accelerators
incorporate on-chip streaming to mitigate off-chip bandwidth limitations,
existing programming models struggle to harness these capabilities effectively.
Low-level interfaces provide fine-grained control but impose significant
development overhead, whereas high-level tile-based languages abstract away
communication details, restricting optimization and forcing compilers to
reconstruct the intended dataflow. We present Dato, a Python-embedded,
task-based programming model for dataflow accelerators that elevates data
communication and sharding to first-class type constructs. Developers write
programs as a graph of tasks connected via explicit stream types, with sharded
inputs specified using layout types. These tasks are first mapped virtually
onto the accelerator's spatial fabric, and the compiler then generates a
physical mapping that respects hardware constraints. Experimental results on
both AMD Ryzen AI NPU and Alveo FPGA devices demonstrate that Dato achieves
high performance while significantly reducing the burden of writing optimized
code. On the NPU, Dato attains up to 84% hardware utilization for GEMM and
delivers a 2.81x speedup on attention kernels compared to a state-of-the-art
commercial framework. On the FPGA, Dato surpasses leading frameworks in
performance when generating custom systolic arrays, achieving 98% of the
theoretical peak performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Termination Analysis of Linear-Constraint Programs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amir M. Ben-Amram, Samir Genaim, Joël Ouaknine, James Worrell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This Survey provides an overview of techniques in termination analysis for
programs with numerical variables and transitions defined by linear
constraints. This subarea of program analysis is challenging due to the
existence of undecidable problems, and this Survey systematically explores
approaches that mitigate this inherent difficulty. These include foundational
decidability results, the use of ranking functions, and disjunctive
well-founded transition invariants. The Survey also discusses non-termination
witnesses, used to prove that a program will not halt. We examine the
algorithmic and complexity aspects of these methods, showing how different
approaches offer a trade-off between expressive power and computational
complexity. The Survey does not discuss how termination analysis is performed
on real-world programming languages, nor does it consider more expressive
abstract models that include non-linear arithmetic, probabilistic choice, or
term rewriting systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pacing Types: Safe Monitoring of Asynchronous Streams 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.06724v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.06724v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florian Kohn, Arthur Correnson, Jan Baumeister, Bernd Finkbeiner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stream-based monitoring is a real-time safety assurance mechanism for complex
cyber-physical systems such as unmanned aerial vehicles. In this context, a
monitor aggregates streams of input data from sensors and other sources to give
real-time statistics and assessments of the system's health. Since monitors are
safety-critical components, it is crucial to ensure that they are free of
potential runtime errors. One of the central challenges in designing reliable
stream-based monitors is to deal with the asynchronous nature of data streams:
in concrete applications, the different sensors being monitored produce values
at different speeds, and it is the monitor's responsibility to correctly react
to the asynchronous arrival of different streams of values. To ease this
process, modern frameworks for stream-based monitoring such as RTLola feature
an expressive specification language that allows to finely specify data
synchronization policies. While this feature dramatically simplifies the design
of monitors, it can also lead to subtle runtime errors. To mitigate this issue,
this paper presents pacing types, a novel type system implemented in RTLola to
ensure that monitors for asynchronous streams are well-behaved at runtime. We
formalize the essence of pacing types for a core fragment of RTLola, and
present a soundness proof of the pacing type system using a new logical
relation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Software Model Checking via Summary-Guided Search (Extended Version) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2508.15137v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2508.15137v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruijie Fang, Zachary Kincaid, Thomas Reps
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we describe a new software model-checking algorithm called GPS.
GPS treats the task of model checking a program as a directed search of the
program states, guided by a compositional, summary-based static analysis. The
summaries produced by static analysis are used both to prune away infeasible
paths and to drive test generation to reach new, unexplored program states. GPS
can find both proofs of safety and counter-examples to safety (i.e., inputs
that trigger bugs), and features a novel two-layered search strategy that
renders it particularly efficient at finding bugs in programs featuring long,
input-dependent error paths. To make GPS refutationally complete (in the sense
that it will find an error if one exists, if it is allotted enough time), we
introduce an instrumentation technique and show that it helps GPS achieve
refutation-completeness without sacrificing overall performance. We benchmarked
GPS on a diverse suite of benchmarks including programs from the Software
Verification Competition (SV-COMP), from prior literature, as well as synthetic
programs based on examples in this paper. We found that our implementation of
GPS outperforms state-of-the-art software model checkers (including the top
performers in SV-COMP ReachSafety-Loops category), both in terms of the number
of benchmarks solved and in terms of running time.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended version of paper in OOPSLA 2025 (with typo and stylistic
  fixes compared to v2 manuscript). 37 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Specification-Guided Repair of Arithmetic Errors in Dafny Programs using
  <span class="highlight-title">LLM</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2507.03659v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2507.03659v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Valentina Wu, Alexandra Mendes, Alexandre Abreu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Debugging and repairing faults when programs fail to formally verify can be
complex and time-consuming. Automated Program Repair (APR) can ease this burden
by automatically identifying and fixing faults. However, traditional APR
techniques often rely on test suites for validation, but these may not capture
all possible scenarios. In contrast, formal specifications provide strong
correctness criteria, enabling more effective automated repair.
  In this paper, we present an APR tool for Dafny, a verification-aware
programming language that uses formal specifications - including
pre-conditions, post-conditions, and invariants - as oracles for fault
localization and repair. Assuming the correctness of the specifications and
focusing on arithmetic bugs, we localize faults through a series of steps,
which include using Hoare logic to determine the state of each statement within
the program, and applying Large Language Models (LLMs) to synthesize candidate
fixes. The models considered are GPT-4o mini, Llama 3, Mistral 7B, and Llemma
7B.
  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny
programs. Our tool achieves 89.6% fault localization coverage and GPT-4o mini
yields the highest repair success rate of 74.18%. These results highlight the
potential of combining formal reasoning with LLM-based program synthesis for
automated program repair.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-09-07T00:00:00Z">2025-09-07</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Programming Languages
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can <span class="highlight-title">Large Language Model</span>s Help Students Prove Software Correctness? An
  Experimental Study with Dafny 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2506.22370v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2506.22370v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carolina Carreira, Álvaro Silva, Alexandre Abreu, Alexandra Mendes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Students in computing education increasingly use large language models (LLMs)
such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding
tasks, like deductive program verification, remains poorly understood. This
paper investigates how students interact with an LLM when solving formal
verification exercises in Dafny, a language that supports functional
correctness, by allowing programmers to write formal specifications and
automatically verifying that the implementation satisfies the specification. We
conducted a mixed-methods study with master's students enrolled in a formal
methods course. Each participant completed two verification problems, one with
access to a custom ChatGPT interface that logged all interactions, and the
other without. We identified strategies used by successful students and
assessed the level of trust students place in LLMs. Our findings show that
students perform significantly better when using ChatGPT; however, performance
gains are tied to prompt quality. We conclude with practical recommendations
for integrating LLMs into formal methods courses more effectively, including
designing LLM-aware challenges that promote learning rather than substitution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What Challenges Do Developers Face When Using Verification-Aware
  Programming Languages? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2506.23696v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2506.23696v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisco Oliveira, Alexandra Mendes, Carolina Carreira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Software reliability is critical in ensuring that the digital systems we
depend on function correctly. In software development, increasing software
reliability often involves testing. However, for complex and critical systems,
developers can use Design by Contract (DbC) methods to define precise
specifications that software components must satisfy. Verification-Aware (VA)
programming languages support DbC and formal verification at compile-time or
run-time, offering stronger correctness guarantees than traditional testing.
However, despite the strong guarantees provided by VA languages, their adoption
remains limited. In this study, we investigate the barriers to adopting VA
languages by analyzing developer discussions on public forums using topic
modeling techniques. We complement this analysis with a developer survey to
better understand the practical challenges associated with VA languages. Our
findings reveal key obstacles to adoption, including steep learning curves and
usability issues. Based on these insights, we identify actionable
recommendations to improve the usability and accessibility of VA languages. Our
findings suggest that simplifying tool interfaces, providing better educational
materials, and improving integration with everyday development environments
could improve the usability and adoption of these languages. Our work provides
actionable insights for improving the usability of VA languages and making
verification tools more accessible.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Decision Procedure for A Theory of String Sequences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2509.00948v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2509.00948v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Denghang Hu, Taolue Chen, Philipp Rümmer, Fu Song, Zhilin Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The theory of sequences, supported by many SMT solvers, can model program
data types including bounded arrays and lists. Sequences are parameterized by
the element data type and provide operations such as accessing elements,
concatenation, forming sub-sequences and updating elements. Strings and
sequences are intimately related; many operations, e.g., matching a string
according to a regular expression, splitting strings, or joining strings in a
sequence, are frequently used in string-manipulating programs. Nevertheless,
these operations are typically not directly supported by existing SMT solvers,
which instead only consider the generic theory of sequences. In this paper, we
propose a theory of string sequences and study its satisfiability. We show
that, while it is undecidable in general, the decidability can be recovered by
restricting to the straight-line fragment. This is shown by encoding each
string sequence as a string, and each string sequence operation as a
corresponding string operation. We provide pre-image computation for the
resulting string operations with respect to automata, effectively casting it
into the generic OSTRICH string constraint solving framework. We implement the
new decision procedure as a tool $\ostrichseq$, and carry out experiments on
benchmark constraints generated from real-world JavaScript programs,
hand-crafted templates and unit tests. The experiments confirm the efficacy of
our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 2 tables, APLAS 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2025-09-13T05:17:52.090571038Z">
            <a href="https://github.com/MohamedElashri/arxiv/actions">
                <img id="build-timestamp-badge"
                     src="https://img.shields.io/github/actions/workflow/status/NotCraft/ArxivDaily/update-feed.yml?label=2025-09-13 05:17:52 UTC&style=for-the-badge"
                alt="2025-09-13 05:17:52 UTC">
            </a>
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
